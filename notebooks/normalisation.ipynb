{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import zarr\n",
    "import numcodecs\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import era5_data_proc\n",
    "import os\n",
    "\n",
    "RAW_ERA5_PATH = \"/vol/bitbucket/bet20/dataset/era5/global_full\"\n",
    "# RAW_ERA5_PATH = '/work/ec249/ec249/bet20/dataset/era5/global_full'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking MEPS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_mean torch.Size([17])\n",
      "data_std torch.Size([17])\n",
      "flux_mean torch.Size([])\n",
      "flux_std torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import neural_lam.utils\n",
    "\n",
    "stats = neural_lam.utils.load_dataset_stats(\"meps_example\")\n",
    "\n",
    "for k, v in stats.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_mean': tensor([ 9.9905e+04,  1.0110e+05, -2.1808e+05,  3.4544e+05,  7.1781e-01,\n",
       "          7.1459e-01,  2.7186e+02,  2.7192e+02,  2.3915e+02,  2.6271e+02,\n",
       "          2.4146e-01,  8.8596e-01, -2.5360e+00, -3.9970e+00,  6.2696e+00,\n",
       "          8.5077e+02,  5.1629e+04]),\n",
       " 'data_std': tensor([2.4345e+03, 7.6800e+02, 1.0905e+05, 5.0245e+05, 1.4583e-01, 1.6231e-01,\n",
       "         4.8396e+00, 4.4669e+00, 5.4922e+00, 3.9706e+00, 4.3646e+00, 6.7067e+00,\n",
       "         4.2867e+00, 5.2042e+00, 3.1096e+00, 5.9784e+02, 1.0582e+03]),\n",
       " 'flux_mean': tensor(911702.5625),\n",
       " 'flux_std': tensor(1037960.1250)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking ERA5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = torch.load(\"/vol/bitbucket/bet20/neural-lam/data/era5_uk/static/parameter_mean_32.pt\")\n",
    "param2 = torch.load(\"/vol/bitbucket/bet20/neural-lam/data/era5_uk/static/parameter_mean_64.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0165e+05,  1.3330e+05,  1.0130e+05,  7.0351e+04,  5.4557e+04,\n",
       "         3.0270e+04,  1.4183e+04,  1.1059e+03,  3.0181e-06,  3.9068e-06,\n",
       "         3.6811e-05,  3.2273e-04,  7.1151e-04,  1.9590e-03,  3.8835e-03,\n",
       "         6.2932e-03,  2.1575e+02,  2.1831e+02,  2.2008e+02,  2.4069e+02,\n",
       "         2.5225e+02,  2.6771e+02,  2.7597e+02,  2.8352e+02,  8.8710e+00,\n",
       "         1.3517e+01,  1.6234e+01,  1.2451e+01,  1.0400e+01,  7.2419e+00,\n",
       "         5.0889e+00,  1.8382e+00, -8.0580e-01, -1.6731e-01,  5.4722e-01,\n",
       "         1.6034e+00,  1.8559e+00,  2.0115e+00,  2.2037e+00,  1.6394e+00,\n",
       "         3.0533e-04,  2.5111e-04, -4.0914e-03, -7.0206e-03, -7.7413e-03,\n",
       "        -7.5574e-03, -4.8157e-03,  2.7199e-04])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0165e+05,  1.3330e+05,  1.0130e+05,  7.0351e+04,  5.4557e+04,\n",
       "         3.0270e+04,  1.4183e+04,  1.1059e+03,  3.0181e-06,  3.9068e-06,\n",
       "         3.6811e-05,  3.2273e-04,  7.1151e-04,  1.9590e-03,  3.8835e-03,\n",
       "         6.2932e-03,  2.1575e+02,  2.1831e+02,  2.2008e+02,  2.4069e+02,\n",
       "         2.5225e+02,  2.6771e+02,  2.7597e+02,  2.8352e+02,  8.8710e+00,\n",
       "         1.3517e+01,  1.6234e+01,  1.2451e+01,  1.0400e+01,  7.2419e+00,\n",
       "         5.0889e+00,  1.8382e+00, -8.0580e-01, -1.6731e-01,  5.4722e-01,\n",
       "         1.6034e+00,  1.8559e+00,  2.0115e+00,  2.2037e+00,  1.6394e+00,\n",
       "         3.0533e-04,  2.5111e-04, -4.0914e-03, -7.0206e-03, -7.7413e-03,\n",
       "        -7.5574e-03, -4.8157e-03,  2.7199e-04])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_mean torch.Size([48])\n",
      "data_std torch.Size([48])\n",
      "flux_mean torch.Size([1])\n",
      "flux_std torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_mean': tensor([ 2.0165e+05,  1.3330e+05,  1.0130e+05,  7.0351e+04,  5.4557e+04,\n",
       "          3.0270e+04,  1.4183e+04,  1.1059e+03,  3.0181e-06,  3.9068e-06,\n",
       "          3.6811e-05,  3.2273e-04,  7.1151e-04,  1.9590e-03,  3.8835e-03,\n",
       "          6.2932e-03,  2.1575e+02,  2.1831e+02,  2.2008e+02,  2.4069e+02,\n",
       "          2.5225e+02,  2.6771e+02,  2.7597e+02,  2.8352e+02,  8.8710e+00,\n",
       "          1.3517e+01,  1.6234e+01,  1.2451e+01,  1.0400e+01,  7.2419e+00,\n",
       "          5.0889e+00,  1.8382e+00, -8.0580e-01, -1.6731e-01,  5.4722e-01,\n",
       "          1.6034e+00,  1.8559e+00,  2.0115e+00,  2.2037e+00,  1.6394e+00,\n",
       "          3.0533e-04,  2.5111e-04, -4.0914e-03, -7.0206e-03, -7.7413e-03,\n",
       "         -7.5574e-03, -4.8157e-03,  2.7199e-04]),\n",
       " 'data_std': tensor([3.3787e+03, 2.5270e+03, 2.5154e+03, 1.9997e+03, 1.6560e+03, 3.3821e+03,\n",
       "         1.0073e+03, 9.5701e+02, 1.4693e-07, 1.5479e-06, 3.0733e-05, 2.7484e-04,\n",
       "         5.8946e-04, 1.4523e-03, 1.8634e-03, 2.0277e-03, 5.9726e+00, 5.3841e+00,\n",
       "         4.7269e+00, 6.0901e+00, 6.2083e+00, 6.2644e+00, 5.5163e+00, 4.7451e+00,\n",
       "         1.3634e+01, 1.0777e+01, 1.7134e+01, 1.4292e+01, 1.1879e+01, 9.2212e+00,\n",
       "         8.4463e+00, 6.4601e+00, 7.9487e+00, 1.1088e+01, 1.9157e+01, 1.5668e+01,\n",
       "         1.2724e+01, 9.5532e+00, 8.3160e+00, 6.5469e+00, 1.9910e-02, 4.7554e-02,\n",
       "         1.1698e-01, 2.5115e-01, 2.9177e-01, 3.0834e-01, 3.0258e-01, 9.6546e-02]),\n",
       " 'flux_mean': tensor([0.]),\n",
       " 'flux_std': tensor([1.])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neural_lam.utils\n",
    "\n",
    "stats = neural_lam.utils.load_dataset_stats(\"era5_uk\")\n",
    "\n",
    "for k, v in stats.items():\n",
    "    print(k, v.shape)\n",
    "    \n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5 Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/vol/bitbucket/bet20/dataset/era5/global_full/2022_01.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_02.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_03.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_04.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_05.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_06.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_07.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_08.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_09.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_10.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_11.nc',\n",
       " '/vol/bitbucket/bet20/dataset/era5/global_full/2022_12.nc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_files = glob.glob(f'{RAW_ERA5_PATH}/2022*.nc')\n",
    "nc_files.sort()\n",
    "nc_files = nc_files[:12]\n",
    "nc_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing xarray sum method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarray_sum = np.array([0]) # (N_vars, N_levels)\n",
    "np_sum = np.array([0]) # (N_vars, N_levels)\n",
    "total_points = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 8)\n",
      "(6, 8, 124, 65, 57)\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_01.nc\n",
      "459420\n",
      "(6, 8)\n",
      "(6, 8, 112, 65, 57)\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_02.nc\n",
      "414960\n",
      "(6, 8)\n",
      "(6, 8, 124, 65, 57)\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_03.nc\n",
      "459420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for i in range(len(nc_files[:3])):\n",
    "    data = xr.open_dataset(nc_files[i])\n",
    "    data = era5_data_proc.uk_subset(data)\n",
    "\n",
    "    num_points = len(data['time']) * len(data[\"latitude\"]) * len(data[\"longitude\"])\n",
    "    total_points = total_points + num_points\n",
    "\n",
    "    sums = np.array([data[var].sum(['time', 'latitude', 'longitude']).values for var in data.data_vars])\n",
    "    print(sums.shape)\n",
    "    xarray_sum = xarray_sum + sums\n",
    "    \n",
    "    vals = data.to_array().values\n",
    "    vals = np.transpose(vals, (0, 2, 1, 3, 4))\n",
    "    print(vals.shape)\n",
    "    np_sum = np_sum + np.sum(vals, axis=(2, 3, 4))\n",
    "\n",
    "    print(nc_files[i])\n",
    "    print(num_points)\n",
    "    \n",
    "np.isclose(xarray_sum, np_sum).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA5 Normalisation from Xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_01.nc\n",
      "459420\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_02.nc\n",
      "414960\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_03.nc\n",
      "459420\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_04.nc\n",
      "444600\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_05.nc\n",
      "459420\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_06.nc\n",
      "444600\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_07.nc\n",
      "459420\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_08.nc\n",
      "459420\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_09.nc\n",
      "444600\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_10.nc\n",
      "459420\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_11.nc\n",
      "444600\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_12.nc\n",
      "459420\n"
     ]
    }
   ],
   "source": [
    "var_sums = np.array([0]) # (N_vars, N_levels)\n",
    "total_points = 0\n",
    "\n",
    "for i in range(len(nc_files)):\n",
    "    data = xr.open_dataset(nc_files[i])\n",
    "    data = era5_data_proc.uk_subset(data)\n",
    "\n",
    "    num_points = len(data['time']) * len(data[\"latitude\"]) * len(data[\"longitude\"])\n",
    "    total_points = total_points + num_points\n",
    "\n",
    "    vals = data.to_array().values # (N_vars, N_times, N_levels, N_lats, N_lons)\n",
    "    vals = np.transpose(vals, (0, 2, 1, 3, 4)) # (N_vars, N_levels, N_times, N_lats, N_lons)\n",
    "    var_sums = var_sums + np.sum(vals, axis=(2, 3, 4)) # (N_vars, N_levels)\n",
    "    \n",
    "    print(nc_files[i])\n",
    "    print(num_points)\n",
    "    \n",
    "var_means = var_sums / total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5409300"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09015224e+12,  7.20641034e+11,  5.47670102e+11,\n",
       "         3.80296571e+11,  2.94897002e+11,  1.64101978e+11,\n",
       "         7.65836121e+10,  5.85896535e+09],\n",
       "       [ 1.63359959e+01,  2.11206421e+01,  1.97379381e+02,\n",
       "         1.73464944e+03,  3.83042161e+03,  1.05280708e+04,\n",
       "         2.09490841e+04,  3.39356692e+04],\n",
       "       [ 1.16613773e+09,  1.18031132e+09,  1.19003267e+09,\n",
       "         1.30140368e+09,  1.36391536e+09,  1.44728626e+09,\n",
       "         1.49239670e+09,  1.53337186e+09],\n",
       "       [ 5.06569929e+07,  7.46620240e+07,  8.92589810e+07,\n",
       "         6.85779214e+07,  5.73118468e+07,  4.00946581e+07,\n",
       "         2.82847254e+07,  1.02825966e+07],\n",
       "       [-3.63395765e+06, -1.94027327e+05,  3.80659153e+06,\n",
       "         9.34574615e+06,  1.05767191e+07,  1.12408657e+07,\n",
       "         1.21226413e+07,  9.01224060e+06],\n",
       "       [ 1.48082852e+03,  7.19104635e+02, -2.41637899e+04,\n",
       "        -4.21965911e+04, -4.66380283e+04, -4.53147993e+04,\n",
       "        -2.97861556e+04,  3.68742678e+02]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = torch.load(\"/vol/bitbucket/bet20/neural-lam/data/era5_uk/static/parameter_sum.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.9293e+06,  3.9194e+06,  2.9788e+06,  2.0686e+06,  1.6042e+06,\n",
       "         8.9007e+05,  4.1705e+05,  3.2518e+04,  8.8743e-05,  1.1488e-04,\n",
       "         1.0824e-03,  9.4895e-03,  2.0921e-02,  5.7604e-02,  1.1419e-01,\n",
       "         1.8505e-01,  6.3438e+03,  6.4193e+03,  6.4711e+03,  7.0772e+03,\n",
       "         7.4172e+03,  7.8718e+03,  8.1145e+03,  8.3365e+03,  2.6084e+02,\n",
       "         3.9746e+02,  4.7735e+02,  3.6611e+02,  3.0579e+02,  2.1294e+02,\n",
       "         1.4964e+02,  5.4050e+01, -2.3694e+01, -4.9195e+00,  1.6091e+01,\n",
       "         4.7146e+01,  5.4570e+01,  5.9147e+01,  6.4797e+01,  4.8204e+01,\n",
       "         8.9780e-03,  7.3838e-03, -1.2030e-01, -2.0643e-01, -2.2763e-01,\n",
       "        -2.2222e-01, -1.4160e-01,  7.9976e-03])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums / total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_means_flat = var_means.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01532960e+05,  1.33222604e+05,  1.01246021e+05,  7.03042115e+04,\n",
       "        5.45166662e+04,  3.03370082e+04,  1.41577676e+04,  1.08312820e+03,\n",
       "        3.01998335e-06,  3.90450558e-06,  3.64888953e-05,  3.20679097e-04,\n",
       "        7.08117800e-04,  1.94629080e-03,  3.87279021e-03,  6.27357869e-03,\n",
       "        2.15580155e+02,  2.18200380e+02,  2.19997535e+02,  2.40586339e+02,\n",
       "        2.52142673e+02,  2.67555184e+02,  2.75894608e+02,  2.83469554e+02,\n",
       "        9.36479635e+00,  1.38025297e+01,  1.65010225e+01,  1.26777811e+01,\n",
       "        1.05950579e+01,  7.41217128e+00,  5.22890677e+00,  1.90091076e+00,\n",
       "       -6.71798135e-01, -3.58692116e-02,  7.03712409e-01,  1.72771822e+00,\n",
       "        1.95528425e+00,  2.07806291e+00,  2.24107394e+00,  1.66606411e+00,\n",
       "        2.73756035e-04,  1.32938575e-04, -4.46708260e-03, -7.80074891e-03,\n",
       "       -8.62182321e-03, -8.37720209e-03, -5.50647138e-03,  6.81682801e-05])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_means_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0165e+05,  1.3330e+05,  1.0130e+05,  7.0351e+04,  5.4557e+04,\n",
       "         3.0270e+04,  1.4183e+04,  1.1059e+03,  3.0181e-06,  3.9068e-06,\n",
       "         3.6811e-05,  3.2273e-04,  7.1151e-04,  1.9590e-03,  3.8835e-03,\n",
       "         6.2932e-03,  2.1575e+02,  2.1831e+02,  2.2008e+02,  2.4069e+02,\n",
       "         2.5225e+02,  2.6771e+02,  2.7597e+02,  2.8352e+02,  8.8710e+00,\n",
       "         1.3517e+01,  1.6234e+01,  1.2451e+01,  1.0400e+01,  7.2419e+00,\n",
       "         5.0889e+00,  1.8382e+00, -8.0580e-01, -1.6731e-01,  5.4722e-01,\n",
       "         1.6034e+00,  1.8559e+00,  2.0115e+00,  2.2037e+00,  1.6394e+00,\n",
       "         3.0533e-04,  2.5111e-04, -4.0914e-03, -7.0206e-03, -7.7413e-03,\n",
       "        -7.5574e-03, -4.8157e-03,  2.7199e-04])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[\"data_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.78497981e-02, -5.49517264e-02, -5.81295177e-02, -6.67404324e-02,\n",
       "       -7.36404897e-02,  2.19520870e-01, -1.80437461e-01, -2.10392325e+00,\n",
       "        6.38323152e-02, -5.90654638e-02, -8.81713980e-01, -6.38511983e-01,\n",
       "       -4.79285271e-01, -6.55473173e-01, -2.75568534e-01, -3.12530227e-01,\n",
       "       -7.65058840e-02, -5.11741518e-02, -3.53004133e-02, -4.22951863e-02,\n",
       "       -4.23602706e-02, -5.80539910e-02, -2.56345328e-02, -1.60478954e-02,\n",
       "        5.27338579e+00,  2.06821929e+00,  1.61669667e+00,  1.78957325e+00,\n",
       "        1.84405534e+00,  2.29692162e+00,  2.67706836e+00,  3.30052266e+00,\n",
       "       -1.99460922e+01, -3.66431718e+02,  2.22381464e+01,  7.19700542e+00,\n",
       "        5.08440630e+00,  3.20155668e+00,  1.66960261e+00,  1.60263596e+00,\n",
       "       -1.15336896e+01, -8.88954073e+01,  8.40951681e+00,  1.00011321e+01,\n",
       "        1.02129109e+01,  9.78610260e+00,  1.25452183e+01, -2.98996600e+02])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(var_means.reshape(-1) - stats[\"data_mean\"].numpy()) / var_means.reshape(-1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(var_means.reshape(-1), stats[\"data_mean\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_01.nc\n",
      "459420\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_02.nc\n",
      "459420\n",
      "/vol/bitbucket/bet20/dataset/era5/global_full/2022_03.nc\n",
      "459420\n"
     ]
    }
   ],
   "source": [
    "var_stds = np.array([0]) # (N_vars, N_levels)\n",
    "for i in range(len(nc_files[:3])):\n",
    "    data = xr.open_dataset(nc_files[i])\n",
    "    data = era5_data_proc.uk_subset(data)\n",
    "\n",
    "    vals = data.to_array().values # (N_vars, N_times, N_levels, N_lats, N_lons)\n",
    "    vals = np.transpose(vals, (0, 2, 1, 3, 4)) # (N_vars, N_levels, N_times, N_lats, N_lons)\n",
    "    var_squared_diff = (vals - var_means.reshape(*var_means.shape, 1, 1, 1)) ** 2\n",
    "    var_stds = var_stds + np.sum(var_squared_diff, axis=(2, 3, 4)) # (N_vars, N_levels)\n",
    "    \n",
    "    print(nc_files[i])\n",
    "    print(num_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.98566816e+05,  1.31345204e+05,  9.99637114e+04,\n",
       "         6.94915794e+04,  5.39460403e+04,  3.31474312e+04,\n",
       "         1.41598198e+04,  1.26508139e+03],\n",
       "       [ 2.98321743e-06,  3.56682817e-06,  1.98416057e-05,\n",
       "         1.88308410e-04,  4.45394453e-04,  1.11086685e-03,\n",
       "         2.72969379e-03,  4.69097381e-03],\n",
       "       [ 2.11742015e+02,  2.14685919e+02,  2.16439728e+02,\n",
       "         2.36899708e+02,  2.48358562e+02,  2.62084934e+02,\n",
       "         2.72406160e+02,  2.79824492e+02],\n",
       "       [ 2.52679674e+01,  1.99496947e+01,  1.96528285e+01,\n",
       "         1.57890576e+01,  1.36483263e+01,  1.05181391e+01,\n",
       "         7.96240956e+00,  3.91867843e+00],\n",
       "       [-2.01051010e+00, -2.21252477e+00, -2.24673299e+00,\n",
       "        -3.94239711e-01,  3.00932753e-01,  8.27003147e-01,\n",
       "         1.69441152e+00,  2.29910446e+00],\n",
       "       [ 2.05483847e-03,  3.22094799e-03,  4.52772609e-04,\n",
       "         8.94847508e-04, -2.17357494e-03, -6.33947440e-03,\n",
       "        -5.22065071e-03, -1.16850669e-03]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA5 Normalisation with dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from neural_lam.era5_dataset import ERA5UKDataset\n",
    "from neural_lam import utils\n",
    "\n",
    "dataset = \"era5_uk_full\"\n",
    "batch_size = 2\n",
    "n_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = utils.load_static_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5464e+03, 2.0264e+03, 2.2975e+03, 2.0187e+03, 1.7620e+03, 5.8213e+03,\n",
       "        1.2267e+03, 1.1808e+03, 1.6962e-07, 1.1838e-06, 1.2919e-05, 1.5098e-04,\n",
       "        3.6187e-04, 9.0703e-04, 1.3290e-03, 1.1877e-03, 6.1122e+00, 5.6558e+00,\n",
       "        3.5887e+00, 4.8513e+00, 5.2299e+00, 5.2967e+00, 4.2371e+00, 2.8118e+00,\n",
       "        1.4652e+01, 1.2807e+01, 1.9964e+01, 1.7005e+01, 1.4406e+01, 1.1302e+01,\n",
       "        9.8326e+00, 7.3897e+00, 1.1996e+01, 1.2976e+01, 2.1520e+01, 1.8191e+01,\n",
       "        1.5043e+01, 1.1692e+01, 9.7814e+00, 7.3720e+00, 3.0445e-02, 6.3717e-02,\n",
       "        1.3932e-01, 2.6964e-01, 3.2182e-01, 3.4959e-01, 3.4065e-01, 1.1852e-01])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "static[\"data_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ERA5UKDataset(\n",
    "    dataset,\n",
    "    split=\"train\",\n",
    "    standardize=False,\n",
    ")  # Without standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    ds, batch_size, shuffle=False, num_workers=n_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 180/716 [00:10<00:32, 16.52it/s]\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "squares = []\n",
    "flux_means = []\n",
    "flux_squares = []\n",
    "i = 0\n",
    "LIMIT = (31 * 4 + 28 * 4 + 31 * 4) // batch_size\n",
    "for init_batch, target_batch, forcing_batch in tqdm(loader):\n",
    "    if i == LIMIT:\n",
    "        break\n",
    "    i += 1\n",
    "    batch = torch.cat(\n",
    "        (init_batch, target_batch), dim=1\n",
    "    )  # (N_batch, N_t, N_grid, d_features)\n",
    "    means.append(torch.mean(batch, dim=(1, 2)))  # (N_batch, d_features,)\n",
    "    squares.append(\n",
    "        torch.mean(batch**2, dim=(1, 2))\n",
    "    )  # (N_batch, d_features,)\n",
    "\n",
    "\n",
    "mean = torch.mean(torch.cat(means, dim=0), dim=0)  # (d_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test MEPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from neural_lam.weather_dataset import WeatherDataset\n",
    "\n",
    "dataset_name = \"meps_example\"\n",
    "batch_size = 2\n",
    "n_workers = 4\n",
    "\n",
    "train_set = WeatherDataset(\n",
    "    dataset_name,\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "dataiter = iter(train_loader)\n",
    "init_states, target_states, forcing = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3705, 48])\n",
      "torch.Size([2, 19, 63784, 17])\n",
      "torch.Size([6, 3705, 12])\n"
     ]
    }
   ],
   "source": [
    "print(init_states.shape)\n",
    "print(target_states.shape)\n",
    "print(forcing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ERA5 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from neural_lam.era5_dataset import ERA5UKDataset\n",
    "\n",
    "dataset_name = \"era5_uk_full\"\n",
    "batch_size = 2\n",
    "n_workers = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.9736e+05,  1.3203e+05,  1.0197e+05,  ..., -2.6944e-01,\n",
       "           -2.1301e-01, -1.2030e-02],\n",
       "          [ 1.9744e+05,  1.3210e+05,  1.0204e+05,  ..., -2.9039e-01,\n",
       "           -1.7324e-01, -3.4319e-03],\n",
       "          [ 1.9754e+05,  1.3218e+05,  1.0212e+05,  ..., -2.5708e-01,\n",
       "           -6.5231e-02,  1.8601e-02],\n",
       "          ...,\n",
       "          [ 2.0049e+05,  1.3320e+05,  1.0142e+05,  ...,  4.6545e-02,\n",
       "            4.2540e-01, -9.6399e-02],\n",
       "          [ 2.0052e+05,  1.3320e+05,  1.0142e+05,  ...,  1.3091e-01,\n",
       "            2.2012e-01, -3.8899e-02],\n",
       "          [ 2.0055e+05,  1.3319e+05,  1.0142e+05,  ...,  1.5402e-01,\n",
       "           -2.2430e-01,  9.8133e-02]],\n",
       "\n",
       "         [[ 1.9758e+05,  1.3228e+05,  1.0215e+05,  ..., -1.1360e-01,\n",
       "            1.1694e-01, -1.1252e-01],\n",
       "          [ 1.9765e+05,  1.3235e+05,  1.0221e+05,  ..., -9.8804e-03,\n",
       "            1.9138e-02, -1.3778e-01],\n",
       "          [ 1.9772e+05,  1.3242e+05,  1.0227e+05,  ...,  7.9325e-02,\n",
       "           -6.4693e-02, -1.1628e-01],\n",
       "          ...,\n",
       "          [ 2.0032e+05,  1.3314e+05,  1.0145e+05,  ...,  3.2437e-01,\n",
       "            6.2047e-01,  8.0937e-02],\n",
       "          [ 2.0036e+05,  1.3316e+05,  1.0146e+05,  ...,  2.5935e-01,\n",
       "            7.3977e-01,  1.0243e-01],\n",
       "          [ 2.0039e+05,  1.3318e+05,  1.0146e+05,  ...,  3.3082e-01,\n",
       "            6.9678e-01,  1.6262e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9309e+05,  1.2685e+05,  9.5603e+04,  ...,  2.3680e-01,\n",
       "            1.7176e-01,  7.7234e-02],\n",
       "          [ 1.9330e+05,  1.2699e+05,  9.5703e+04,  ...,  1.3230e-01,\n",
       "            1.7480e-01,  7.2464e-02],\n",
       "          [ 1.9352e+05,  1.2713e+05,  9.5812e+04,  ...,  8.3305e-02,\n",
       "            1.3230e-01,  6.5960e-02],\n",
       "          ...,\n",
       "          [ 2.0116e+05,  1.3273e+05,  9.9477e+04,  ..., -4.0538e-01,\n",
       "           -5.3937e-01, -2.2196e-01],\n",
       "          [ 2.0120e+05,  1.3283e+05,  9.9647e+04,  ...,  3.8857e-01,\n",
       "           -4.0885e-01, -2.6142e-01],\n",
       "          [ 2.0124e+05,  1.3291e+05,  9.9849e+04,  ...,  8.0527e-01,\n",
       "            5.7721e-02, -1.4868e-01]],\n",
       "\n",
       "         [[ 1.9368e+05,  1.2791e+05,  9.6971e+04,  ...,  6.0321e-01,\n",
       "            3.5215e-01,  4.2545e-02],\n",
       "          [ 1.9389e+05,  1.2806e+05,  9.7112e+04,  ...,  5.0608e-01,\n",
       "            2.7453e-01,  4.5147e-02],\n",
       "          [ 1.9408e+05,  1.2820e+05,  9.7247e+04,  ...,  3.3307e-01,\n",
       "            1.4618e-01,  4.0377e-02],\n",
       "          ...,\n",
       "          [ 2.0138e+05,  1.3250e+05,  9.9589e+04,  ..., -5.7015e-01,\n",
       "           -6.3476e-01, -9.7513e-02],\n",
       "          [ 2.0141e+05,  1.3259e+05,  9.9702e+04,  ...,  1.3059e-02,\n",
       "           -3.0391e-01, -1.4651e-01],\n",
       "          [ 2.0143e+05,  1.3267e+05,  9.9827e+04,  ...,  2.7323e-01,\n",
       "           -3.5681e-01, -2.3887e-01]]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = ERA5UKDataset(\n",
    "    dataset_name,\n",
    "    pred_length=1,\n",
    "    split=\"train\",\n",
    "    standardize=False,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_workers,\n",
    ")\n",
    "\n",
    "print(len(train_loader))\n",
    "dataiter = iter(train_loader)\n",
    "init_states, target_states, forcing = next(dataiter)\n",
    "init_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.9441,  2.0760,  1.3319,  ...,  0.7017,  0.3570, -0.1295],\n",
       "          [ 2.9493,  2.1082,  1.3931,  ...,  0.7084,  0.3536, -0.0852],\n",
       "          [ 2.9531,  2.1405,  1.4528,  ...,  0.6300,  0.3673, -0.0114],\n",
       "          ...,\n",
       "          [ 2.9980,  3.2260,  2.6165,  ...,  0.7734,  0.6669, -0.6510],\n",
       "          [ 2.9916,  3.2405,  2.6165,  ...,  1.1254,  0.8740, -0.1344],\n",
       "          [ 2.9865,  3.2550,  2.6151,  ...,  1.1254,  0.8997,  1.0021]],\n",
       "\n",
       "         [[ 2.9018,  2.1098,  1.4884,  ..., -2.6577,  0.3793, -0.2131],\n",
       "          [ 2.9095,  2.1502,  1.5538,  ..., -3.5968,  0.0506, -0.4788],\n",
       "          [ 2.9159,  2.1921,  1.6164,  ..., -3.8821, -0.5536, -0.5477],\n",
       "          ...,\n",
       "          [ 2.9005,  3.1873,  2.5810,  ..., -0.1290,  0.9322, -0.0507],\n",
       "          [ 2.8941,  3.1970,  2.5781,  ...,  0.0828,  1.2078,  0.2100],\n",
       "          [ 2.8877,  3.2099,  2.5753,  ...,  0.1179,  1.2232,  1.0464]]],\n",
       "\n",
       "\n",
       "        [[[ 3.1045,  1.8560,  0.5640,  ..., -0.2758, -0.7146, -0.1385],\n",
       "          [ 3.1032,  1.8738,  0.6039,  ..., -0.1671, -0.7923, -0.0963],\n",
       "          [ 3.1019,  1.8916,  0.6453,  ..., -0.0942, -0.8760, -0.1469],\n",
       "          ...,\n",
       "          [ 2.9810,  3.3770,  2.8463,  ...,  0.3477,  0.7029,  0.2031],\n",
       "          [ 2.9810,  3.4012,  2.8620,  ...,  0.4878,  0.7983,  0.5447],\n",
       "          [ 2.9797,  3.4271,  2.8748,  ...,  0.6722,  0.7748,  1.0550]],\n",
       "\n",
       "         [[ 3.1636,  1.9175,  0.5911,  ..., -0.1128,  0.0221, -0.2228],\n",
       "          [ 3.1598,  1.9417,  0.6395,  ..., -0.1070,  0.2656, -0.1343],\n",
       "          [ 3.1572,  1.9643,  0.6923,  ..., -0.1042,  0.3992, -0.0120],\n",
       "          ...,\n",
       "          [ 3.0247,  3.4820,  2.9219,  ...,  0.4463,  0.6325, -0.5729],\n",
       "          [ 3.0183,  3.5014,  2.9418,  ...,  0.7452,  0.8086, -0.3367],\n",
       "          [ 3.0131,  3.5208,  2.9589,  ...,  1.0597,  0.8878,  0.4899]]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = ERA5UKDataset(\n",
    "    dataset_name,\n",
    "    pred_length=1,\n",
    "    split=\"train\",\n",
    "    standardize=True,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_workers,\n",
    ")\n",
    "\n",
    "print(len(train_loader))\n",
    "dataiter = iter(train_loader)\n",
    "init_states, target_states, forcing = next(dataiter)\n",
    "init_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"/vol/bitbucket/bet20/neural-lam/data/era5_uk_full/samples/train\"\n",
    "files = glob.glob(os.path.join(path, \"*.npy\"))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3705, 48])\n",
      "torch.Size([2, 1, 3705, 48])\n",
      "torch.Size([2, 1, 3705, 0])\n"
     ]
    }
   ],
   "source": [
    "print(init_states.shape)\n",
    "print(target_states.shape)\n",
    "print(forcing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "torch.Size([2, 2, 3705, 48])\n",
      "torch.Size([2, 28, 3705, 48])\n",
      "torch.Size([2, 28, 3705, 0])\n"
     ]
    }
   ],
   "source": [
    "val_set = ERA5UKDataset(\n",
    "    dataset_name,\n",
    "    pred_length=28,\n",
    "    split=\"val\",\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_workers,\n",
    ")\n",
    "\n",
    "valiter = iter(val_loader)\n",
    "init_states, target_states, forcing = next(valiter)\n",
    "\n",
    "print(len(val_set))\n",
    "print(init_states.shape)\n",
    "print(target_states.shape)\n",
    "print(forcing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time step data\n",
    "sample_dir_path = \"data/era5_uk/samples/train\"\n",
    "sample_files = glob.glob(f'{sample_dir_path}/*.npy')\n",
    "sample_files.sort()\n",
    "sample_files = [os.path.basename(f)[:-4] for f in sample_files]\n",
    "sample_times = [datetime.datetime.strptime(f, '%Y%m%d%H%M%S') for f in sample_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20221231180000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(sample_times)):\n",
    "    delta = sample_times[i] - sample_times[i-1]\n",
    "    if delta != datetime.timedelta(hours=6):\n",
    "        print(f\"Missing time step: {sample_times[i-1]} -> {sample_times[i]} ({delta})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir_path = \"data/era5_uk/samples/val\"\n",
    "# directories = [name for name in os.listdir(sample_dir_path)]\n",
    "# directories.sort()\n",
    "# directories\n",
    "val_months = [\"01\", \"04\", \"07\", \"10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/era5_uk_full/samples/val/04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/era5_uk_full/samples/val/04/20230401000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230401060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230401120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230401180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230402000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230402060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230402120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230402180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230403000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230403060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230403120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230403180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230404000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230404060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230404120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230404180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230405000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230405060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230405120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230405180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230406000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230406060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230406120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230406180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230407000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230407060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230407120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230407180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230408000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230408060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230408120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230408180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230409000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230409060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230409120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230409180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230410000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230410060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230410120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230410180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230411000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230411060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230411120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230411180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230412000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230412060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230412120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230412180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230413000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230413060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230413120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230413180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230414000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230414060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230414120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230414180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230415000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230415060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230415120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230415180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230416000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230416060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230416120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230416180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230417000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230417060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230417120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230417180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230418000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230418060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230418120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230418180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230419000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230419060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230419120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230419180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230420000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230420060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230420120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230420180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230421000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230421060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230421120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230421180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230422000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230422060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230422120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230422180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230423000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230423060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230423120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230423180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230424000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230424060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230424120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230424180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230425000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230425060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230425120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230425180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230426000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230426060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230426120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230426180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230427000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230427060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230427120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230427180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230428000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230428060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230428120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230428180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230429000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230429060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230429120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230429180000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230430000000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230430060000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230430120000.npy',\n",
       " 'data/era5_uk_full/samples/val/04/20230430180000.npy']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "month_path = os.path.join(sample_dir_path, val_months[1])\n",
    "print(month_path)\n",
    "sample_files = glob.glob(f'{month_path}/*.npy')\n",
    "sample_files.sort()\n",
    "sample_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Specify the source and destination directories\n",
    "src_dir = 'data/era5_uk_full/samples/train/'\n",
    "dst_dir = 'data/era5_uk_full/samples/val/01'\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# Use glob to get all .npy files that start with 2023 in the source directory\n",
    "files = glob.glob(os.path.join(src_dir, '202301*.npy'))\n",
    "\n",
    "# print(files)\n",
    "# print(len(files))\n",
    "\n",
    "# Move each file to the destination directory\n",
    "for file in files:\n",
    "    shutil.move(file, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "31 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pred_length = 28\n",
    "sample_length = pred_length + 2\n",
    "val_samples = []\n",
    "sample_dir_path = \"./data/era5_uk_full/samples/val\"\n",
    "month_samples = {}\n",
    "\n",
    "for month in val_months:\n",
    "    month_dir = os.path.join(sample_dir_path, month)\n",
    "    data_files = glob.glob(os.path.join(month_dir, \"*.npy\"))\n",
    "    data_files.sort()\n",
    "    month_samples[month] = data_files\n",
    "    n_samples = len(data_files) - sample_length + 1\n",
    "    for i in range(n_samples):\n",
    "        val_samples.append((month, i))\n",
    "    \n",
    "\n",
    "N = len(val_samples)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/era5_uk_full/samples/val/10/20231013180000.npy', 51)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 332\n",
    "month, idx = val_samples[idx]\n",
    "sample_names = month_samples[month]\n",
    "\n",
    "sample_names[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verify number of time steps\n",
    "val_files = glob.glob(f'{src_dir}/10/*.npy')\n",
    "len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_files = glob.glob(f'{src_dir}/*.npy')\n",
    "# val_files.sort()\n",
    "# wanted = [v for v in val_files if \"202301\" in v or \"202310\" in v or \"202304\" in v or \"202307\" in v]\n",
    "# wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
