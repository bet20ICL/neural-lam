{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import os\n",
    "\n",
    "from neural_lam.metrics import wmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, pred_steps, n_grid, d_f = 4, 28, 3000, 128\n",
    "y_hat = torch.rand((batch_size, pred_steps, n_grid, d_f))\n",
    "y = torch.rand((batch_size, pred_steps, n_grid, d_f))\n",
    "pred_std = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "loss1 = torch.mean(wmse(y_hat, y, pred_std))\n",
    "loss2 = torch.mean(wmse(y_hat, y, pred_std), dim=0)\n",
    "loss3 = torch.mean(loss2)\n",
    "print(loss1.shape)\n",
    "print(loss2.shape)\n",
    "print(loss3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(loss1, loss3).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of files in train vs val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "samples_dir = \"/vol/bitbucket/bet20/neural-lam/data/era5_uk/samples/train\"\n",
    "num_files = len(os.listdir(samples_dir))\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 1460 1458\n",
      "365\n"
     ]
    }
   ],
   "source": [
    "total_days = 31 * 7 + 28 + 30 * 4 # Jan, Mar, May, Jul, Aug, Oct, Dec\n",
    "total_time_steps = total_days * 4\n",
    "pred_length = 1\n",
    "sample_length = pred_length + 2\n",
    "total_samples = total_time_steps - sample_length + 1\n",
    "print(total_days, total_time_steps, total_samples)\n",
    "\n",
    "total_batches = math.ceil(total_samples / 4) \n",
    "print(total_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '10', '04', 'other', '07']\n",
      "5\n",
      "492\n"
     ]
    }
   ],
   "source": [
    "samples_dir = \"/vol/bitbucket/bet20/neural-lam/data/era5_uk/samples/val\"\n",
    "dirs = os.listdir(samples_dir)\n",
    "num_files = len(dirs)\n",
    "print(dirs)\n",
    "print(num_files)\n",
    "\n",
    "total_files = 0\n",
    "for m in ['01', '04', '07', '10']:\n",
    "    total_files += len(os.listdir(os.path.join(samples_dir, m)))\n",
    "    \n",
    "print(total_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 492 463\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "total_days = 31 + 30 + 31 + 31\n",
    "total_time_steps = total_days * 4\n",
    "pred_length = 28\n",
    "sample_length = pred_length + 2\n",
    "total_samples = total_time_steps - sample_length + 1\n",
    "print(total_days, total_time_steps, total_samples)\n",
    "\n",
    "total_batches = math.ceil(total_samples / 4) \n",
    "print(total_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "def steps(total_days):\n",
    "    total_time_steps = total_days * 4\n",
    "    pred_length = 28\n",
    "    sample_length = pred_length + 2\n",
    "    total_samples = total_time_steps - sample_length + 1\n",
    "    # total_batches = math.ceil(total_samples / 4)\n",
    "    return total_samples\n",
    "\n",
    "days = [31, 30, 31, 31]\n",
    "total_samples = sum([steps(d) for d in days])\n",
    "total_batches = math.ceil(total_samples / 4)\n",
    "print(total_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/era5_uk_reduced/samples/train\"\n",
    "nc_files = glob.glob(f'{constants.DATASET_PATH}/global/*.nc')\n",
    "print(nc_files)\n",
    "data = xr.open_dataset(nc_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from era5_data_proc import uk_subset\n",
    "uk_data = uk_subset(data)\n",
    "uk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_data['longitude'] = xr.where(uk_data['longitude'] > 180, uk_data['longitude'] - 360, uk_data['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_data.isel(time=0).to_array().values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = uk_data.latitude.values\n",
    "latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = uk_data.longitude.values\n",
    "longitudes = np.where(longitudes > 180, longitudes - 360, longitudes)\n",
    "longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = uk_data.latitude.values\n",
    "longitudes = uk_data.longitude.values\n",
    "# print(latitudes.shape, longitudes.shape)\n",
    "\n",
    "t_lat = torch.from_numpy(latitudes)\n",
    "t_lon = torch.from_numpy(longitudes)\n",
    "\n",
    "lat_lon_grid = torch.stack(\n",
    "    torch.meshgrid(t_lat, t_lon, indexing=\"ij\"), dim=-1\n",
    ").permute(2, 1, 0)\n",
    "\n",
    "lat_lon_grid.shape # (2, lon, lat) or (2, x, y)\n",
    "\n",
    "grid_array = lat_lon_grid.numpy()\n",
    "grid_array.shape\n",
    "# np.save(\"nwp_xy.npy\", grid_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"data/era5_uk_reduced/static/nwp_xy.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path=\"data/era5_uk_reduced/samples/train\"\n",
    "sample_name=\"20220101000000\"\n",
    "sample_path=f\"{processed_data_path}/{sample_name}.npy\"\n",
    "\n",
    "sample=np.load(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat, lon\n",
    "input_res = (721, 1440)\n",
    "latitudes = torch.linspace(-90, 90, steps=input_res[0])\n",
    "latitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = torch.linspace(-180, 180, steps=input_res[1] + 1)[1:]\n",
    "longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_grid = torch.stack(\n",
    "    torch.meshgrid(latitudes, longitudes, indexing=\"ij\"), dim=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(np.load(\"data/era5_global/static/nwp_xy.npy\")).permute(2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lat_lon_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = lat_lon_grid.permute(2, 0, 1)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.view(2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "icospheres_path = \"data/era5_global/icospheres.json\"\n",
    "with open(icospheres_path, \"r\") as f:\n",
    "    loaded_dict = json.load(f)\n",
    "    icospheres = {\n",
    "        key: (np.array(value) if isinstance(value, list) else value)\n",
    "        for key, value in loaded_dict.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in icospheres.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icospheres[\"order_0_face_centroid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphcast_utils import latlon2xyz\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "input_res = (721, 1440)\n",
    "latitudes = torch.linspace(-90, 90, steps=input_res[0])\n",
    "longitudes = torch.linspace(-180, 180, steps=input_res[1] + 1)[1:]\n",
    "lat_lon_grid = torch.stack(\n",
    "    torch.meshgrid(latitudes, longitudes, indexing=\"ij\"), dim=-1\n",
    ")\n",
    "lat_lon_grid_flat = lat_lon_grid.permute(2, 0, 1).view(2, -1).permute(1, 0)\n",
    "lat_lon_grid_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_grid = latlon2xyz(lat_lon_grid_flat) # (lat*lon, 3)\n",
    "n_nbrs = 4\n",
    "neighbors = NearestNeighbors(n_neighbors=n_nbrs).fit(\n",
    "    icospheres[\"order_\" + str(6) + \"_vertices\"] # (40962, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = neighbors.kneighbors(cartesian_grid) # (lat*lon, n_nbrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_grid_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, dst = [], []\n",
    "for i in range(len(cartesian_grid)):\n",
    "    for j in range(n_nbrs):\n",
    "        if distances[i][j] <= 0.6 * edge_len:\n",
    "            src.append(i)\n",
    "            dst.append(indices[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"data/era5_uk_reduced/samples/train/20220101000000.npy\").shape # (6, 7, 65, 57) (levels, variables, lat, lon)\n",
    "np.load(\"data/_era5_uk_reduced/samples/train/20220101000000.npy\").shape # (6, 7, 721, 1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_bbox = {\n",
    "    \"lat_max\": 63,\n",
    "    \"lat_min\": 47,\n",
    "    \"lon_max\": 4,\n",
    "    \"lon_min\": -10,\n",
    "}\n",
    "\n",
    "torch.linspace(uk_bbox[\"lat_min\"], uk_bbox[\"lat_max\"], steps=65) # (65,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linspace(uk_bbox[\"lon_min\"], uk_bbox[\"lon_max\"], steps=57) # (65,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming larger is your larger tensor and smaller is your smaller tensor\n",
    "larger = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "smaller = torch.tensor([[1, 2], [7, 8]])\n",
    "\n",
    "# Expand dimensions for broadcasting\n",
    "larger_exp = larger.unsqueeze(1)\n",
    "smaller_exp = smaller.unsqueeze(0)\n",
    "\n",
    "# Compare all pairs of rows\n",
    "matches = torch.all(larger_exp == smaller_exp, dim=-1)\n",
    "\n",
    "# Get indices of matching rows\n",
    "indices = torch.where(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensors\n",
    "larger_tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]])\n",
    "smaller_tensor = torch.tensor([[5.0, 6.0], [3.0, 4.0], [1.0, 2.0]])\n",
    "\n",
    "def find_subset_indices(larger, smaller):\n",
    "    \"\"\"\n",
    "    finds the indices of the smaller tensor in the larger tensor\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i in range(smaller.size(0)):\n",
    "        index = torch.where(torch.all(larger == smaller[i], dim=1))[0]\n",
    "        if index.size(0) == 0:\n",
    "            raise ValueError(\"The smaller tensor is not a subset of the larger tensor\")\n",
    "        indices.append(index.item())\n",
    "    return indices\n",
    "\n",
    "indices = find_subset_indices(larger_tensor, smaller_tensor)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assuming tensor1 and tensor2 are your tensors\n",
    "tensor1 = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "tensor2 = torch.tensor([[1, 2], [7, 8], [9, 10]])\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "array1 = tensor1.numpy()\n",
    "array2 = tensor2.numpy()\n",
    "\n",
    "# Find common rows\n",
    "common_rows = np.intersect1d(array1, array2, axis=0)\n",
    "\n",
    "# Convert back to tensor\n",
    "common_rows_tensor = torch.from_numpy(common_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(10))\n",
    "b = [3, 2 , 1]\n",
    "\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_lam.constants as constants\n",
    "w_dict = {\n",
    "    \"2\": 1.0,\n",
    "    \"0\": 0.1,\n",
    "    \"65\": 0.065,\n",
    "    \"1000\": 0.1,\n",
    "    \"850\": 0.05,\n",
    "    \"500\": 0.03,\n",
    "}\n",
    "w_list = np.array(\n",
    "    [w_dict[par.split(\"_\")[-2]] for par in constants.PARAM_NAMES]\n",
    ")\n",
    "\n",
    "w_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neural_lam.constants as constants\n",
    "# Create parameter weights based on height\n",
    "# based on fig A.1 in graph cast paper\n",
    "w_dict = {\n",
    "    \"2\": 1.0,\n",
    "    \"0\": 0.1,\n",
    "    \"65\": 0.065,\n",
    "    \"1000\": 0.1,\n",
    "    \"850\": 0.05,\n",
    "    \"500\": 0.03,\n",
    "}\n",
    "w_list = np.array(\n",
    "    [w_dict[par.split(\"_\")[-2]] for par in constants.PARAM_NAMES]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in zip(w_list, constants.PARAM_NAMES):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_lam.constants import MEPSConstants\n",
    "\n",
    "MEPSConstants.GRID_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Icospheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "icospheres_path = \"data/era5_uk/icospheres.json\"\n",
    "\n",
    "with open(icospheres_path, \"r\") as f:\n",
    "    loaded_dict = json.load(f)\n",
    "    icospheres = {\n",
    "        key: (np.array(value) if isinstance(value, list) else value)\n",
    "        for key, value in loaded_dict.items()\n",
    "    }\n",
    "    print(f\"Opened pre-computed graph at {icospheres_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in icospheres.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([key for key in icospheres.keys() if \"faces\" in key]) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1440 * 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5])\n",
    "b = torch.tensor([6, 7, 8, 9, 10])\n",
    "\n",
    "torch.stack((a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "import torch\n",
    "import numpy as np\n",
    " \n",
    "\n",
    "def create_heterograph(\n",
    "    src: List, dst: List, labels: str, dtype: torch.dtype = torch.int32\n",
    ") -> DGLGraph:\n",
    "    \"\"\"Creates a heterogeneous DGL graph from an adj matrix in COO format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src : List\n",
    "        List of source nodes\n",
    "    dst : List\n",
    "        List of destination nodes\n",
    "    labels : str\n",
    "        Label of the edge type\n",
    "    dtype : torch.dtype, optional\n",
    "        Graph index data type, by default torch.int32\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DGLGraph\n",
    "        The dgl Graph.\n",
    "    \"\"\"\n",
    "    graph = dgl.heterograph({labels: (\"coo\", (src, dst))}, idtype=dtype)\n",
    "    return graph\n",
    "\n",
    "src = [np.array([0, 1, 2]), np.array([3, 4, 5])]\n",
    "dst = [np.array([1, 2, 3]), np.array([4, 5, 6])]\n",
    "\n",
    "graph = create_heterograph(src, dst, (\"mesh\", \"m2g\", \"grid\"), dtype=torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridiculous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "           5663073       gpu submit_j    bet20 PD       0:00      1 (Priority)\n",
    "           5663071       gpu submit_j    bet20 PD       0:00      1 (Resources)\n",
    "     5662324_[0-4]       gpu    F2mIF  qwang33 PD       0:00      1 (Priority)\n",
    "     5662323_[1-5]       gpu    F2mIF  qwang33 PD       0:00      1 (Priority)\n",
    "           5660755       gpu 24layers   cc2040 PD       0:00      2 (Priority)\n",
    "           5660861       gpu    r-c16 yiweiche PD       0:00      1 (Priority)\n",
    "           5660862       gpu    r-c32 yiweiche PD       0:00      1 (Priority)\n",
    "           5660900       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660898       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660899       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660897       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660893       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660894       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660895       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660896       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660889       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660890       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660891       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660892       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660888       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660887       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660886       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662524       gpu sr327mod gpw2-ec2 PD       0:00      4 (Priority)\n",
    "           5662502       gpu    uw_G1   aa2201 PD       0:00      1 (Priority)\n",
    "           5662706       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662707       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662704       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662705       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662702       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662703       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662701       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662699       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662700       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662697       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662698       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662696       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662694       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662695       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662692       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662693       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662691       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662689       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662690       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662687       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662688       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662686       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662684       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662685       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662682       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662683       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662681       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662679       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662680       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662677       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662678       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662675       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662676       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662671       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662672       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662673       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662674       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662669       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662670       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662665       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662666       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662667       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662668       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662663       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662664       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662659       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662660       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662661       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662662       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662657       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662658       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662656       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662653       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662654       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662655       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662651       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662652       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662648       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662649       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662650       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662646       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662647       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662643       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662644       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662645       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662642       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662641       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662638       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662639       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662640       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662635       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662636       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662637       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662633       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662634       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662631       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662632       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662629       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662630       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662627       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662628       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662626       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662625       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662624       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662623       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662622       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662621       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662620       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662619       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662618       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662617       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662616       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662615       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662614       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662613       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662612       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662611       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662610       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662609       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662608       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5663082       gpu uw_G1_ra   aa2201 PD       0:00      1 (Priority)\n",
    "           5663081       gpu bio512_2   aa2201 PD       0:00      1 (Priority)\n",
    "           5663080       gpu   bio512   aa2201 PD       0:00      1 (Priority)\n",
    "           5663078       gpu ast512_2   aa2201 PD       0:00      1 (Priority)\n",
    "           5663076       gpu   ast512   aa2201 PD       0:00      1 (Priority)\n",
    "           5662472       gpu   MUMAX3      cpy PD       0:00      1 (Priority)\n",
    "           5662195       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662191       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662192       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662193       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662194       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662190       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662186       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662187       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662188       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662189       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662182       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662183       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662184       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662185       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662201       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662200       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662199       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662198       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662197       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662196       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662473       gpu   MUMAX3      cpy PD       0:00      1 (Dependency)\n",
    "           5662598       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662597       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662596       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662595       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662594       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662593       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662592       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662591       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662590       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662589       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5631081       gpu HemKtest   julian  R 13-03:43:08      1 r2i6n0\n",
    "           5662497       gpu run_XCLI xingran0  R    4:51:28      4 r2i4n[1-4]\n",
    "           5660733       gpu     mace juraskov  R   11:50:40      1 r2i5n7\n",
    "           5660732       gpu     mace juraskov  R   11:59:47      1 r2i7n1\n",
    "           5660731       gpu     mace juraskov  R   12:05:27      1 r2i5n7\n",
    "         5660551_5       gpu    F2mIF  qwang33  R   13:54:11      1 r2i6n3\n",
    "         5660551_4       gpu    F2mIF  qwang33  R   14:21:30      1 r2i4n0\n",
    "           5660715       gpu     mace juraskov  R   12:37:19      1 r2i4n5\n",
    "           5660716       gpu     mace juraskov  R   12:37:19      1 r2i4n5\n",
    "           5660717       gpu     mace juraskov  R   12:37:19      1 r2i4n5\n",
    "           5660718       gpu     mace juraskov  R   12:37:19      1 r2i4n5\n",
    "           5660719       gpu     mace juraskov  R   12:37:19      1 r2i4n8\n",
    "           5660720       gpu     mace juraskov  R   12:37:19      1 r2i4n8\n",
    "           5660721       gpu     mace juraskov  R   12:37:19      1 r2i4n8\n",
    "           5660722       gpu     mace juraskov  R   12:37:19      1 r2i4n8\n",
    "           5660723       gpu     mace juraskov  R   12:37:19      1 r2i6n1\n",
    "           5660724       gpu     mace juraskov  R   12:37:19      1 r2i6n1\n",
    "           5660725       gpu     mace juraskov  R   12:37:19      1 r2i6n1\n",
    "           5660726       gpu     mace juraskov  R   12:37:19      1 r2i6n1\n",
    "           5660727       gpu     mace juraskov  R   12:37:19      1 r2i6n2\n",
    "           5660728       gpu     mace juraskov  R   12:37:19      1 r2i6n2\n",
    "           5660729       gpu     mace juraskov  R   12:37:19      1 r2i6n2\n",
    "           5660730       gpu     mace juraskov  R   12:37:19      1 r2i6n2\n",
    "           5660711       gpu     mace juraskov  R   13:54:11      1 r2i7n3\n",
    "           5660712       gpu     mace juraskov  R   13:54:11      1 r2i7n3\n",
    "           5660713       gpu     mace juraskov  R   13:54:11      1 r2i7n3\n",
    "           5660714       gpu     mace juraskov  R   13:54:11      1 r2i7n3\n",
    "         5660551_3       gpu    F2mIF  qwang33  R   15:29:46      1 r2i7n0\n",
    "         5660551_1       gpu    F2mIF  qwang33  R   16:04:11      1 r2i7n2\n",
    "         5660551_2       gpu    F2mIF  qwang33  R   16:04:11      1 r2i7n4\n",
    "           5660710       gpu     mace juraskov  R   14:24:38      1 r2i6n0\n",
    "           5660709       gpu     mace juraskov  R   14:50:53      1 r2i5n6\n",
    "           5660708       gpu     mace juraskov  R   16:15:23      1 r2i6n0\n",
    "           5660707       gpu     mace juraskov  R   16:16:24      1 r2i6n0\n",
    "           5662126       gpu   myvenv zhenyaza  R   11:03:18      1 r2i4n6\n",
    "           5662127       gpu   myvenv zhenyaza  R   11:03:18      1 r2i5n8\n",
    "           5660706       gpu     mace juraskov  R   17:55:58      1 r2i7n6\n",
    "           5660705       gpu     mace juraskov  R   18:04:32      1 r2i7n6\n",
    "           5660704       gpu     mace juraskov  R   20:16:54      1 r2i6n4\n",
    "           5660703       gpu     mace juraskov  R   20:18:55      1 r2i6n4\n",
    "           5660702       gpu     mace juraskov  R   20:26:30      1 r2i5n6\n",
    "           5660701       gpu     mace juraskov  R   20:33:04      1 r2i5n7\n",
    "           5660699       gpu     mace juraskov  R   21:40:48      1 r2i7n6\n",
    "           5660700       gpu     mace juraskov  R   21:40:48      1 r2i7n6\n",
    "           5660698       gpu     mace juraskov  R   23:17:14      1 r2i4n7\n",
    "           5656524       gpu     mace juraskov  R 3-21:13:59      1 r2i5n3\n",
    "           5660697       gpu     mace juraskov  R 1-00:47:30      1 r2i5n6\n",
    "           5660696       gpu     mace juraskov  R 1-00:50:01      1 r2i5n6\n",
    "           5660695       gpu     mace juraskov  R 1-01:24:47      1 r2i4n7\n",
    "           5660694       gpu     mace juraskov  R 1-02:37:16      1 r2i6n4\n",
    "           5660693       gpu     mace juraskov  R 1-02:37:17      1 r2i6n4\n",
    "         5662323_0       gpu    F2mIF  qwang33  R    7:29:11      1 r2i5n4\n",
    "           5660753       gpu sr327mod gpw2-ec2  R    7:51:43      4 r2i6n[6-8],r2i7n5\n",
    "           5660692       gpu     mace juraskov  R 1-03:30:36      1 r2i4n7\n",
    "           5660686       gpu     mace juraskov  R 1-03:31:06      1 r2i4n7\n",
    "           5660687       gpu     mace juraskov  R 1-03:31:06      1 r2i7n1\n",
    "           5660688       gpu     mace juraskov  R 1-03:31:06      1 r2i7n1\n",
    "           5660689       gpu     mace juraskov  R 1-03:31:06      1 r2i5n1\n",
    "           5660690       gpu     mace juraskov  R 1-03:31:06      1 r2i5n1\n",
    "           5660691       gpu     mace juraskov  R 1-03:31:06      1 r2i5n7\n",
    "           5660885       gpu     traj xr223_ci  R    5:20:49      1 r2i7n7\n",
    "           5660884       gpu     traj xr223_ci  R    5:21:19      1 r2i7n7\n",
    "           5660883       gpu     traj xr223_ci  R    8:02:01      1 r2i7n7\n",
    "           5660882       gpu     traj xr223_ci  R    8:03:31      1 r2i7n7\n",
    "           5660881       gpu     traj xr223_ci  R   11:17:41      1 r2i7n1\n",
    "           5657937       gpu       pd yiweiche  R 3-07:08:49      1 r2i5n1\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
