{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import era5_data_proc\n",
    "from neural_lam import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/work/ec249/ec249/bet20/dataset/era5/global_full/2022_01.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_02.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_03.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_04.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_05.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_06.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_07.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_08.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_09.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_10.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_11.nc',\n",
       " '/work/ec249/ec249/bet20/dataset/era5/global_full/2022_12.nc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_ERA5_PATH = constants.ERA5UKConstants.RAW_ERA5_PATH\n",
    "nc_files = glob.glob(f'{RAW_ERA5_PATH}/2022*.nc')\n",
    "nc_files.sort()\n",
    "nc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "datasets = [\n",
    "    era5_data_proc.uk_subset(xr.open_dataset(file))\n",
    "    for file in nc_files\n",
    "]\n",
    "\n",
    "# Concatenate the datasets along the time dimension\n",
    "combined_ds = xr.concat(datasets, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-02-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-03-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-04-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-05-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-06-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-07-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-08-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-09-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-10-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-11-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n",
      "2022-12-01T00:00:00.000000000\n",
      "Number of levels in dataset: 8\n",
      "[  50  150  250  400  500  600  850 1000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset.time.values[0])\n",
    "    print(f\"Number of levels in dataset: {len(dataset.level)}\")\n",
    "    print(dataset.level.values)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mean and Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute mean and standard deviation\n",
    "def compute_mean_std(ds, dims):\n",
    "    mean = ds.mean(dim=dims)\n",
    "    std = ds.std(dim=dims)\n",
    "    return mean, std\n",
    "\n",
    "# Compute mean and standard deviation for each variable at each level\n",
    "# results = {}\n",
    "means = []\n",
    "stds = []\n",
    "for var in combined_ds.data_vars:\n",
    "    mean, std = compute_mean_std(combined_ds[var], dims=['time', 'latitude', 'longitude'])\n",
    "    means.append(mean.values)\n",
    "    stds.append(std.values)\n",
    "    # results[var] = {\n",
    "    #     'mean': mean,\n",
    "    #     'std': std\n",
    "    # }\n",
    "\n",
    "# # Display results\n",
    "# for var, stats in results.items():\n",
    "#     print(f\"Variable: {var}\")\n",
    "#     print(\"Mean:\")\n",
    "#     print(stats['mean'])\n",
    "#     print(\"Standard Deviation:\")\n",
    "#     print(stats['std'])\n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01532960e+05,  1.33222604e+05,  1.01246021e+05,  7.03042115e+04,\n",
       "        5.45166662e+04,  4.10747350e+04,  1.41577676e+04,  1.08312820e+03,\n",
       "        3.01998335e-06,  3.90450558e-06,  3.64888953e-05,  3.20679097e-04,\n",
       "        7.08117800e-04,  1.24631686e-03,  3.87279021e-03,  6.27357869e-03,\n",
       "        2.15580155e+02,  2.18200380e+02,  2.19997535e+02,  2.40586339e+02,\n",
       "        2.52142673e+02,  2.61119689e+02,  2.75894608e+02,  2.83469554e+02,\n",
       "        9.36479635e+00,  1.38025297e+01,  1.65010225e+01,  1.26777811e+01,\n",
       "        1.05950579e+01,  8.83134447e+00,  5.22890677e+00,  1.90091076e+00,\n",
       "       -6.71798135e-01, -3.58692116e-02,  7.03712409e-01,  1.72771822e+00,\n",
       "        1.95528425e+00,  2.07750081e+00,  2.24107394e+00,  1.66606411e+00,\n",
       "        2.73957534e-04,  1.32868569e-04, -4.46702399e-03, -7.80065913e-03,\n",
       "       -8.62185625e-03, -9.01868128e-03, -5.50647184e-03,  6.83435912e-05])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_flat = np.array(means).flatten()\n",
    "means_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.46378385e+03, 2.57340550e+03, 2.54697655e+03, 2.02629590e+03,\n",
       "       1.68029847e+03, 1.41371064e+03, 1.02573033e+03, 9.72442797e+02,\n",
       "       1.47679801e-07, 1.54255947e-06, 3.05828048e-05, 2.73782873e-04,\n",
       "       5.87589168e-04, 9.94811332e-04, 1.85786913e-03, 2.02595486e-03,\n",
       "       6.05043424e+00, 5.41659327e+00, 4.73106649e+00, 6.11794738e+00,\n",
       "       6.24122823e+00, 6.00192917e+00, 5.52586870e+00, 4.73478234e+00,\n",
       "       1.39659060e+01, 1.09072252e+01, 1.72058059e+01, 1.43505817e+01,\n",
       "       1.19191308e+01, 1.01928534e+01, 8.50726774e+00, 6.46494004e+00,\n",
       "       7.99076174e+00, 1.11337571e+01, 1.91737833e+01, 1.56930378e+01,\n",
       "       1.27484754e+01, 1.07688719e+01, 8.38618506e+00, 6.57868864e+00,\n",
       "       2.03153799e-02, 4.82544792e-02, 1.17774963e-01, 2.52615396e-01,\n",
       "       2.94146765e-01, 3.07425664e-01, 3.05509455e-01, 9.67055372e-02])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds_flat = np.array(stds).flatten()\n",
    "stds_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Numpy Calculated Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_mean torch.Size([48])\n",
      "data_std torch.Size([48])\n",
      "flux_mean torch.Size([1])\n",
      "flux_std torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_mean': tensor([ 2.0165e+05,  1.3330e+05,  1.0130e+05,  7.0351e+04,  5.4557e+04,\n",
       "          4.1109e+04,  1.4183e+04,  1.1059e+03,  3.0181e-06,  3.9068e-06,\n",
       "          3.6811e-05,  3.2273e-04,  7.1151e-04,  1.2518e-03,  3.8835e-03,\n",
       "          6.2932e-03,  2.1575e+02,  2.1831e+02,  2.2008e+02,  2.4069e+02,\n",
       "          2.5225e+02,  2.6122e+02,  2.7597e+02,  2.8352e+02,  8.8710e+00,\n",
       "          1.3517e+01,  1.6234e+01,  1.2451e+01,  1.0400e+01,  8.6597e+00,\n",
       "          5.0889e+00,  1.8382e+00, -8.0580e-01, -1.6731e-01,  5.4722e-01,\n",
       "          1.6034e+00,  1.8559e+00,  1.9991e+00,  2.2037e+00,  1.6394e+00,\n",
       "          3.0554e-04,  2.5106e-04, -4.0914e-03, -7.0205e-03, -7.7413e-03,\n",
       "         -8.1350e-03, -4.8157e-03,  2.7216e-04]),\n",
       " 'data_std': tensor([3.3787e+03, 2.5270e+03, 2.5154e+03, 1.9997e+03, 1.6560e+03, 1.3914e+03,\n",
       "         1.0073e+03, 9.5701e+02, 1.4693e-07, 1.5479e-06, 3.0733e-05, 2.7484e-04,\n",
       "         5.8946e-04, 9.9799e-04, 1.8634e-03, 2.0277e-03, 5.9726e+00, 5.3841e+00,\n",
       "         4.7269e+00, 6.0901e+00, 6.2083e+00, 5.9719e+00, 5.5163e+00, 4.7451e+00,\n",
       "         1.3634e+01, 1.0777e+01, 1.7134e+01, 1.4292e+01, 1.1879e+01, 1.0156e+01,\n",
       "         8.4463e+00, 6.4601e+00, 7.9487e+00, 1.1088e+01, 1.9157e+01, 1.5668e+01,\n",
       "         1.2724e+01, 1.0742e+01, 8.3160e+00, 6.5469e+00, 1.9910e-02, 4.7554e-02,\n",
       "         1.1698e-01, 2.5115e-01, 2.9177e-01, 3.0420e-01, 3.0258e-01, 9.6546e-02]),\n",
       " 'flux_mean': tensor([0.]),\n",
       " 'flux_std': tensor([1.])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neural_lam.utils\n",
    "\n",
    "stats = neural_lam.utils.load_dataset_stats(\"era5_uk\")\n",
    "\n",
    "for k, v in stats.items():\n",
    "    print(k, v.shape)\n",
    "    \n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01649547e+05,  1.33295812e+05,  1.01304875e+05,  7.03511328e+04,\n",
       "        5.45568125e+04,  4.11093438e+04,  1.41833135e+04,  1.10591638e+03,\n",
       "        3.01805562e-06,  3.90681180e-06,  3.68106230e-05,  3.22726672e-04,\n",
       "        7.11511704e-04,  1.25182618e-03,  3.88346240e-03,  6.29318552e-03,\n",
       "        2.15745087e+02,  2.18312042e+02,  2.20075195e+02,  2.40688095e+02,\n",
       "        2.52249481e+02,  2.61221252e+02,  2.75965332e+02,  2.83515045e+02,\n",
       "        8.87095451e+00,  1.35170631e+01,  1.62342510e+01,  1.24509029e+01,\n",
       "        1.03996792e+01,  8.65973282e+00,  5.08892536e+00,  1.83817077e+00,\n",
       "       -8.05795610e-01, -1.67305380e-01,  5.47219813e-01,  1.60337424e+00,\n",
       "        1.85586965e+00,  1.99909222e+00,  2.20365691e+00,  1.63936317e+00,\n",
       "        3.05537367e-04,  2.51055142e-04, -4.09135735e-03, -7.02047860e-03,\n",
       "       -7.74132553e-03, -8.13497882e-03, -4.81566601e-03,  2.72161473e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_means = stats[\"data_mean\"].numpy()\n",
    "np_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.37869092e+03, 2.52698706e+03, 2.51541162e+03, 1.99967993e+03,\n",
       "       1.65598071e+03, 1.39144812e+03, 1.00730133e+03, 9.57011902e+02,\n",
       "       1.46927761e-07, 1.54794157e-06, 3.07325718e-05, 2.74835998e-04,\n",
       "       5.89463685e-04, 9.97988973e-04, 1.86340814e-03, 2.02769018e-03,\n",
       "       5.97259378e+00, 5.38407660e+00, 4.72691774e+00, 6.09014320e+00,\n",
       "       6.20829821e+00, 5.97193956e+00, 5.51631117e+00, 4.74506330e+00,\n",
       "       1.36338682e+01, 1.07769833e+01, 1.71344948e+01, 1.42924862e+01,\n",
       "       1.18788853e+01, 1.01562052e+01, 8.44627666e+00, 6.46008492e+00,\n",
       "       7.94869280e+00, 1.10883484e+01, 1.91570759e+01, 1.56679077e+01,\n",
       "       1.27240753e+01, 1.07422981e+01, 8.31596565e+00, 6.54694510e+00,\n",
       "       1.99098401e-02, 4.75541316e-02, 1.16981812e-01, 2.51145631e-01,\n",
       "       2.91772425e-01, 3.04199249e-01, 3.02577317e-01, 9.65461358e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_stds = stats[\"data_std\"].numpy()\n",
    "np_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare numpy and xarray values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.78497981e-04, -5.49517264e-04, -5.81295177e-04, -6.67404324e-04,\n",
       "       -7.36404897e-04, -8.42579396e-04, -1.80437461e-03, -2.10392325e-02,\n",
       "        6.38323152e-04, -5.90654638e-04, -8.81713980e-03, -6.38511983e-03,\n",
       "       -4.79285271e-03, -4.42047746e-03, -2.75568534e-03, -3.12530227e-03,\n",
       "       -7.65058840e-04, -5.11741518e-04, -3.53004133e-04, -4.22951863e-04,\n",
       "       -4.23602706e-04, -3.88952964e-04, -2.56345328e-04, -1.60478954e-04,\n",
       "        5.27338579e-02,  2.06821929e-02,  1.61669667e-02,  1.78957325e-02,\n",
       "        1.84405534e-02,  1.94321092e-02,  2.67706836e-02,  3.30052266e-02,\n",
       "       -1.99460922e-01, -3.66431718e+00,  2.22381464e-01,  7.19700542e-02,\n",
       "        5.08440630e-02,  3.77417863e-02,  1.66960261e-02,  1.60263596e-02,\n",
       "       -1.15272731e-01, -8.89499860e-01,  8.40977444e-02,  1.00014693e-01,\n",
       "        1.02127743e-01,  9.79857728e-02,  1.25453441e-01, -2.98225302e+00])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(means_flat - np_means) / means_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02456647,  0.01803775,  0.0123931 ,  0.01313528,  0.01447229,\n",
       "        0.01574758,  0.01796671,  0.01586818,  0.00509237, -0.00348907,\n",
       "       -0.0048971 , -0.00384657, -0.00319018, -0.00319421, -0.00298137,\n",
       "       -0.00085654,  0.01286527,  0.00600316,  0.00087692,  0.00454469,\n",
       "        0.00527621,  0.00499666,  0.0017296 , -0.00217137,  0.02377489,\n",
       "        0.01194089,  0.0041446 ,  0.0040483 ,  0.00337655,  0.00359549,\n",
       "        0.00716929,  0.00075099,  0.0052647 ,  0.00407847,  0.00087137,\n",
       "        0.00160135,  0.00191396,  0.00246765,  0.00837322,  0.00482521,\n",
       "        0.01996221,  0.01451363,  0.00673446,  0.00581819,  0.00807196,\n",
       "        0.01049495,  0.00959754,  0.00164832])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(stds_flat - np_stds) / stds_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of files in train vs val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920\n"
     ]
    }
   ],
   "source": [
    "samples_dir = \"./data/era5_uk/samples/train\"\n",
    "num_files = len(os.listdir(samples_dir))\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 1460 1458\n",
      "365\n"
     ]
    }
   ],
   "source": [
    "total_days = 31 * 7 + 28 + 30 * 4 # Jan, Mar, May, Jul, Aug, Oct, Dec\n",
    "total_time_steps = total_days * 4\n",
    "pred_length = 1\n",
    "sample_length = pred_length + 2\n",
    "total_samples = total_time_steps - sample_length + 1\n",
    "print(total_days, total_time_steps, total_samples)\n",
    "\n",
    "total_batches = math.ceil(total_samples / 4) \n",
    "print(total_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '04', '01', '07']\n",
      "4\n",
      "492\n"
     ]
    }
   ],
   "source": [
    "samples_dir = \"./data/era5_uk/samples/val\"\n",
    "dirs = os.listdir(samples_dir)\n",
    "num_files = len(dirs)\n",
    "print(dirs)\n",
    "print(num_files)\n",
    "\n",
    "total_files = 0\n",
    "for m in ['01', '04', '07', '10']:\n",
    "    total_files += len(os.listdir(os.path.join(samples_dir, m)))\n",
    "    \n",
    "print(total_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 492 463\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "total_days = 31 + 30 + 31 + 31\n",
    "total_time_steps = total_days * 4\n",
    "pred_length = 28\n",
    "sample_length = pred_length + 2\n",
    "total_samples = total_time_steps - sample_length + 1\n",
    "print(total_days, total_time_steps, total_samples)\n",
    "\n",
    "total_batches = math.ceil(total_samples / 4) \n",
    "print(total_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "def steps(total_days):\n",
    "    total_time_steps = total_days * 4\n",
    "    pred_length = 28\n",
    "    sample_length = pred_length + 2\n",
    "    total_samples = total_time_steps - sample_length + 1\n",
    "    # total_batches = math.ceil(total_samples / 4)\n",
    "    return total_samples\n",
    "\n",
    "days = [31, 30, 31, 31]\n",
    "total_samples = sum([steps(d) for d in days])\n",
    "total_batches = math.ceil(total_samples / 4)\n",
    "print(total_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import os\n",
    "\n",
    "from neural_lam.metrics import wmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, pred_steps, n_grid, d_f = 4, 28, 3000, 128\n",
    "y_hat = torch.rand((batch_size, pred_steps, n_grid, d_f))\n",
    "y = torch.rand((batch_size, pred_steps, n_grid, d_f))\n",
    "pred_std = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "loss1 = torch.mean(wmse(y_hat, y, pred_std))\n",
    "loss2 = torch.mean(wmse(y_hat, y, pred_std), dim=0)\n",
    "loss3 = torch.mean(loss2)\n",
    "print(loss1.shape)\n",
    "print(loss2.shape)\n",
    "print(loss3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(loss1, loss3).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/era5_uk_reduced/samples/train\"\n",
    "nc_files = glob.glob(f'{constants.DATASET_PATH}/global/*.nc')\n",
    "print(nc_files)\n",
    "data = xr.open_dataset(nc_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from era5_data_proc import uk_subset\n",
    "uk_data = uk_subset(data)\n",
    "uk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_data['longitude'] = xr.where(uk_data['longitude'] > 180, uk_data['longitude'] - 360, uk_data['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_data.isel(time=0).to_array().values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = uk_data.latitude.values\n",
    "latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = uk_data.longitude.values\n",
    "longitudes = np.where(longitudes > 180, longitudes - 360, longitudes)\n",
    "longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = uk_data.latitude.values\n",
    "longitudes = uk_data.longitude.values\n",
    "# print(latitudes.shape, longitudes.shape)\n",
    "\n",
    "t_lat = torch.from_numpy(latitudes)\n",
    "t_lon = torch.from_numpy(longitudes)\n",
    "\n",
    "lat_lon_grid = torch.stack(\n",
    "    torch.meshgrid(t_lat, t_lon, indexing=\"ij\"), dim=-1\n",
    ").permute(2, 1, 0)\n",
    "\n",
    "lat_lon_grid.shape # (2, lon, lat) or (2, x, y)\n",
    "\n",
    "grid_array = lat_lon_grid.numpy()\n",
    "grid_array.shape\n",
    "# np.save(\"nwp_xy.npy\", grid_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"data/era5_uk_reduced/static/nwp_xy.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path=\"data/era5_uk_reduced/samples/train\"\n",
    "sample_name=\"20220101000000\"\n",
    "sample_path=f\"{processed_data_path}/{sample_name}.npy\"\n",
    "\n",
    "sample=np.load(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat, lon\n",
    "input_res = (721, 1440)\n",
    "latitudes = torch.linspace(-90, 90, steps=input_res[0])\n",
    "latitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = torch.linspace(-180, 180, steps=input_res[1] + 1)[1:]\n",
    "longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_grid = torch.stack(\n",
    "    torch.meshgrid(latitudes, longitudes, indexing=\"ij\"), dim=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(np.load(\"data/era5_global/static/nwp_xy.npy\")).permute(2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lat_lon_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = lat_lon_grid.permute(2, 0, 1)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.view(2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "icospheres_path = \"data/era5_global/icospheres.json\"\n",
    "with open(icospheres_path, \"r\") as f:\n",
    "    loaded_dict = json.load(f)\n",
    "    icospheres = {\n",
    "        key: (np.array(value) if isinstance(value, list) else value)\n",
    "        for key, value in loaded_dict.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in icospheres.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icospheres[\"order_0_face_centroid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphcast_utils import latlon2xyz\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "input_res = (721, 1440)\n",
    "latitudes = torch.linspace(-90, 90, steps=input_res[0])\n",
    "longitudes = torch.linspace(-180, 180, steps=input_res[1] + 1)[1:]\n",
    "lat_lon_grid = torch.stack(\n",
    "    torch.meshgrid(latitudes, longitudes, indexing=\"ij\"), dim=-1\n",
    ")\n",
    "lat_lon_grid_flat = lat_lon_grid.permute(2, 0, 1).view(2, -1).permute(1, 0)\n",
    "lat_lon_grid_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_grid = latlon2xyz(lat_lon_grid_flat) # (lat*lon, 3)\n",
    "n_nbrs = 4\n",
    "neighbors = NearestNeighbors(n_neighbors=n_nbrs).fit(\n",
    "    icospheres[\"order_\" + str(6) + \"_vertices\"] # (40962, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = neighbors.kneighbors(cartesian_grid) # (lat*lon, n_nbrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_grid_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, dst = [], []\n",
    "for i in range(len(cartesian_grid)):\n",
    "    for j in range(n_nbrs):\n",
    "        if distances[i][j] <= 0.6 * edge_len:\n",
    "            src.append(i)\n",
    "            dst.append(indices[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"data/era5_uk_reduced/samples/train/20220101000000.npy\").shape # (6, 7, 65, 57) (levels, variables, lat, lon)\n",
    "np.load(\"data/_era5_uk_reduced/samples/train/20220101000000.npy\").shape # (6, 7, 721, 1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_bbox = {\n",
    "    \"lat_max\": 63,\n",
    "    \"lat_min\": 47,\n",
    "    \"lon_max\": 4,\n",
    "    \"lon_min\": -10,\n",
    "}\n",
    "\n",
    "torch.linspace(uk_bbox[\"lat_min\"], uk_bbox[\"lat_max\"], steps=65) # (65,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linspace(uk_bbox[\"lon_min\"], uk_bbox[\"lon_max\"], steps=57) # (65,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming larger is your larger tensor and smaller is your smaller tensor\n",
    "larger = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "smaller = torch.tensor([[1, 2], [7, 8]])\n",
    "\n",
    "# Expand dimensions for broadcasting\n",
    "larger_exp = larger.unsqueeze(1)\n",
    "smaller_exp = smaller.unsqueeze(0)\n",
    "\n",
    "# Compare all pairs of rows\n",
    "matches = torch.all(larger_exp == smaller_exp, dim=-1)\n",
    "\n",
    "# Get indices of matching rows\n",
    "indices = torch.where(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensors\n",
    "larger_tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]])\n",
    "smaller_tensor = torch.tensor([[5.0, 6.0], [3.0, 4.0], [1.0, 2.0]])\n",
    "\n",
    "def find_subset_indices(larger, smaller):\n",
    "    \"\"\"\n",
    "    finds the indices of the smaller tensor in the larger tensor\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i in range(smaller.size(0)):\n",
    "        index = torch.where(torch.all(larger == smaller[i], dim=1))[0]\n",
    "        if index.size(0) == 0:\n",
    "            raise ValueError(\"The smaller tensor is not a subset of the larger tensor\")\n",
    "        indices.append(index.item())\n",
    "    return indices\n",
    "\n",
    "indices = find_subset_indices(larger_tensor, smaller_tensor)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assuming tensor1 and tensor2 are your tensors\n",
    "tensor1 = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "tensor2 = torch.tensor([[1, 2], [7, 8], [9, 10]])\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "array1 = tensor1.numpy()\n",
    "array2 = tensor2.numpy()\n",
    "\n",
    "# Find common rows\n",
    "common_rows = np.intersect1d(array1, array2, axis=0)\n",
    "\n",
    "# Convert back to tensor\n",
    "common_rows_tensor = torch.from_numpy(common_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(10))\n",
    "b = [3, 2 , 1]\n",
    "\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_lam.constants as constants\n",
    "w_dict = {\n",
    "    \"2\": 1.0,\n",
    "    \"0\": 0.1,\n",
    "    \"65\": 0.065,\n",
    "    \"1000\": 0.1,\n",
    "    \"850\": 0.05,\n",
    "    \"500\": 0.03,\n",
    "}\n",
    "w_list = np.array(\n",
    "    [w_dict[par.split(\"_\")[-2]] for par in constants.PARAM_NAMES]\n",
    ")\n",
    "\n",
    "w_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neural_lam.constants as constants\n",
    "# Create parameter weights based on height\n",
    "# based on fig A.1 in graph cast paper\n",
    "w_dict = {\n",
    "    \"2\": 1.0,\n",
    "    \"0\": 0.1,\n",
    "    \"65\": 0.065,\n",
    "    \"1000\": 0.1,\n",
    "    \"850\": 0.05,\n",
    "    \"500\": 0.03,\n",
    "}\n",
    "w_list = np.array(\n",
    "    [w_dict[par.split(\"_\")[-2]] for par in constants.PARAM_NAMES]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in zip(w_list, constants.PARAM_NAMES):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_lam.constants import MEPSConstants\n",
    "\n",
    "MEPSConstants.GRID_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Icospheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "icospheres_path = \"data/era5_uk/icospheres.json\"\n",
    "\n",
    "with open(icospheres_path, \"r\") as f:\n",
    "    loaded_dict = json.load(f)\n",
    "    icospheres = {\n",
    "        key: (np.array(value) if isinstance(value, list) else value)\n",
    "        for key, value in loaded_dict.items()\n",
    "    }\n",
    "    print(f\"Opened pre-computed graph at {icospheres_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in icospheres.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([key for key in icospheres.keys() if \"faces\" in key]) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1440 * 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5])\n",
    "b = torch.tensor([6, 7, 8, 9, 10])\n",
    "\n",
    "torch.stack((a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "import torch\n",
    "import numpy as np\n",
    " \n",
    "\n",
    "def create_heterograph(\n",
    "    src: List, dst: List, labels: str, dtype: torch.dtype = torch.int32\n",
    ") -> DGLGraph:\n",
    "    \"\"\"Creates a heterogeneous DGL graph from an adj matrix in COO format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    src : List\n",
    "        List of source nodes\n",
    "    dst : List\n",
    "        List of destination nodes\n",
    "    labels : str\n",
    "        Label of the edge type\n",
    "    dtype : torch.dtype, optional\n",
    "        Graph index data type, by default torch.int32\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DGLGraph\n",
    "        The dgl Graph.\n",
    "    \"\"\"\n",
    "    graph = dgl.heterograph({labels: (\"coo\", (src, dst))}, idtype=dtype)\n",
    "    return graph\n",
    "\n",
    "src = [np.array([0, 1, 2]), np.array([3, 4, 5])]\n",
    "dst = [np.array([1, 2, 3]), np.array([4, 5, 6])]\n",
    "\n",
    "graph = create_heterograph(src, dst, (\"mesh\", \"m2g\", \"grid\"), dtype=torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridiculous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "           5663073       gpu submit_j    bet20 PD       0:00      1 (Priority)\n",
    "           5663071       gpu submit_j    bet20 PD       0:00      1 (Resources)\n",
    "     5662324_[0-4]       gpu    F2mIF  qwang33 PD       0:00      1 (Priority)\n",
    "     5662323_[1-5]       gpu    F2mIF  qwang33 PD       0:00      1 (Priority)\n",
    "           5660755       gpu 24layers   cc2040 PD       0:00      2 (Priority)\n",
    "           5660861       gpu    r-c16 yiweiche PD       0:00      1 (Priority)\n",
    "           5660862       gpu    r-c32 yiweiche PD       0:00      1 (Priority)\n",
    "           5660900       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660898       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660899       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660897       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660893       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660894       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660895       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660896       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660889       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660890       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660891       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660892       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660888       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660887       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5660886       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662524       gpu sr327mod gpw2-ec2 PD       0:00      4 (Priority)\n",
    "           5662502       gpu    uw_G1   aa2201 PD       0:00      1 (Priority)\n",
    "           5662706       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662707       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662704       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662705       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662702       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662703       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662701       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662699       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662700       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662697       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662698       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662696       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662694       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662695       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662692       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662693       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662691       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662689       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662690       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662687       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662688       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662686       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662684       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662685       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662682       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662683       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662681       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662679       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662680       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662677       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662678       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662675       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662676       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662671       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662672       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662673       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662674       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662669       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662670       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662665       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662666       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662667       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662668       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662663       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662664       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662659       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662660       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662661       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662662       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662657       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662658       gpu P23Hetde   cc2040 PD       0:00      1 (Priority)\n",
    "           5662656       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662653       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662654       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662655       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662651       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662652       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662648       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662649       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662650       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662646       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662647       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662643       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662644       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662645       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662642       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662641       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662638       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662639       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662640       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662635       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662636       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662637       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662633       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662634       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662631       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662632       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662629       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662630       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662627       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662628       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662626       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662625       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662624       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662623       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662622       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662621       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662620       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662619       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662618       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662617       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662616       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662615       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662614       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662613       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662612       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662611       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662610       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662609       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5662608       gpu 3c353_id   cc2040 PD       0:00      1 (Priority)\n",
    "           5663082       gpu uw_G1_ra   aa2201 PD       0:00      1 (Priority)\n",
    "           5663081       gpu bio512_2   aa2201 PD       0:00      1 (Priority)\n",
    "           5663080       gpu   bio512   aa2201 PD       0:00      1 (Priority)\n",
    "           5663078       gpu ast512_2   aa2201 PD       0:00      1 (Priority)\n",
    "           5663076       gpu   ast512   aa2201 PD       0:00      1 (Priority)\n",
    "           5662472       gpu   MUMAX3      cpy PD       0:00      1 (Priority)\n",
    "           5662195       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662191       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662192       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662193       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662194       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662190       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662186       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662187       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662188       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662189       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662182       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662183       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662184       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662185       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662201       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662200       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662199       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662198       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662197       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662196       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662473       gpu   MUMAX3      cpy PD       0:00      1 (Dependency)\n",
    "           5662598       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662597       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662596       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662595       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662594       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662593       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662592       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662591       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662590       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5662589       gpu     traj xr223_ci PD       0:00      1 (Priority)\n",
    "           5631081       gpu HemKtest   julian  R 13-03:43:08      1 r2i6n0\n",
    "           5662497       gpu run_XCLI xingran0  R    4:51:28      4 r2i4n[1-4]\n",
    "           5660733       gpu     mace juraskov  R   11:50:40      1 r2i5n7\n",
    "           5660732       gpu     mace juraskov  R   11:59:47      1 r2i7n1\n",
    "           5660731       gpu     mace juraskov  R   12:05:27      1 r2i5n7\n",
    "         5660551_5       gpu    F2mIF  qwang33  R   13:54:11      1 r2i6n3\n",
    "         5660551_4       gpu    F2mIF  qwang33  R   14:21:30      1 r2i4n0\n",
    "           5660715       gpu     mace juraskov  R   12:37:19      1 r2i4n5\n",
    "           5660716       gpu     mace juraskov  R   12:37:19      1 r2i4n5\n",
    "           5660717       gpu     mace juraskov  R   12:37:19      1 r2i4n5\n",
    "           5660718       gpu     mace juraskov  R   12:37:19      1 r2i4n5\n",
    "           5660719       gpu     mace juraskov  R   12:37:19      1 r2i4n8\n",
    "           5660720       gpu     mace juraskov  R   12:37:19      1 r2i4n8\n",
    "           5660721       gpu     mace juraskov  R   12:37:19      1 r2i4n8\n",
    "           5660722       gpu     mace juraskov  R   12:37:19      1 r2i4n8\n",
    "           5660723       gpu     mace juraskov  R   12:37:19      1 r2i6n1\n",
    "           5660724       gpu     mace juraskov  R   12:37:19      1 r2i6n1\n",
    "           5660725       gpu     mace juraskov  R   12:37:19      1 r2i6n1\n",
    "           5660726       gpu     mace juraskov  R   12:37:19      1 r2i6n1\n",
    "           5660727       gpu     mace juraskov  R   12:37:19      1 r2i6n2\n",
    "           5660728       gpu     mace juraskov  R   12:37:19      1 r2i6n2\n",
    "           5660729       gpu     mace juraskov  R   12:37:19      1 r2i6n2\n",
    "           5660730       gpu     mace juraskov  R   12:37:19      1 r2i6n2\n",
    "           5660711       gpu     mace juraskov  R   13:54:11      1 r2i7n3\n",
    "           5660712       gpu     mace juraskov  R   13:54:11      1 r2i7n3\n",
    "           5660713       gpu     mace juraskov  R   13:54:11      1 r2i7n3\n",
    "           5660714       gpu     mace juraskov  R   13:54:11      1 r2i7n3\n",
    "         5660551_3       gpu    F2mIF  qwang33  R   15:29:46      1 r2i7n0\n",
    "         5660551_1       gpu    F2mIF  qwang33  R   16:04:11      1 r2i7n2\n",
    "         5660551_2       gpu    F2mIF  qwang33  R   16:04:11      1 r2i7n4\n",
    "           5660710       gpu     mace juraskov  R   14:24:38      1 r2i6n0\n",
    "           5660709       gpu     mace juraskov  R   14:50:53      1 r2i5n6\n",
    "           5660708       gpu     mace juraskov  R   16:15:23      1 r2i6n0\n",
    "           5660707       gpu     mace juraskov  R   16:16:24      1 r2i6n0\n",
    "           5662126       gpu   myvenv zhenyaza  R   11:03:18      1 r2i4n6\n",
    "           5662127       gpu   myvenv zhenyaza  R   11:03:18      1 r2i5n8\n",
    "           5660706       gpu     mace juraskov  R   17:55:58      1 r2i7n6\n",
    "           5660705       gpu     mace juraskov  R   18:04:32      1 r2i7n6\n",
    "           5660704       gpu     mace juraskov  R   20:16:54      1 r2i6n4\n",
    "           5660703       gpu     mace juraskov  R   20:18:55      1 r2i6n4\n",
    "           5660702       gpu     mace juraskov  R   20:26:30      1 r2i5n6\n",
    "           5660701       gpu     mace juraskov  R   20:33:04      1 r2i5n7\n",
    "           5660699       gpu     mace juraskov  R   21:40:48      1 r2i7n6\n",
    "           5660700       gpu     mace juraskov  R   21:40:48      1 r2i7n6\n",
    "           5660698       gpu     mace juraskov  R   23:17:14      1 r2i4n7\n",
    "           5656524       gpu     mace juraskov  R 3-21:13:59      1 r2i5n3\n",
    "           5660697       gpu     mace juraskov  R 1-00:47:30      1 r2i5n6\n",
    "           5660696       gpu     mace juraskov  R 1-00:50:01      1 r2i5n6\n",
    "           5660695       gpu     mace juraskov  R 1-01:24:47      1 r2i4n7\n",
    "           5660694       gpu     mace juraskov  R 1-02:37:16      1 r2i6n4\n",
    "           5660693       gpu     mace juraskov  R 1-02:37:17      1 r2i6n4\n",
    "         5662323_0       gpu    F2mIF  qwang33  R    7:29:11      1 r2i5n4\n",
    "           5660753       gpu sr327mod gpw2-ec2  R    7:51:43      4 r2i6n[6-8],r2i7n5\n",
    "           5660692       gpu     mace juraskov  R 1-03:30:36      1 r2i4n7\n",
    "           5660686       gpu     mace juraskov  R 1-03:31:06      1 r2i4n7\n",
    "           5660687       gpu     mace juraskov  R 1-03:31:06      1 r2i7n1\n",
    "           5660688       gpu     mace juraskov  R 1-03:31:06      1 r2i7n1\n",
    "           5660689       gpu     mace juraskov  R 1-03:31:06      1 r2i5n1\n",
    "           5660690       gpu     mace juraskov  R 1-03:31:06      1 r2i5n1\n",
    "           5660691       gpu     mace juraskov  R 1-03:31:06      1 r2i5n7\n",
    "           5660885       gpu     traj xr223_ci  R    5:20:49      1 r2i7n7\n",
    "           5660884       gpu     traj xr223_ci  R    5:21:19      1 r2i7n7\n",
    "           5660883       gpu     traj xr223_ci  R    8:02:01      1 r2i7n7\n",
    "           5660882       gpu     traj xr223_ci  R    8:03:31      1 r2i7n7\n",
    "           5660881       gpu     traj xr223_ci  R   11:17:41      1 r2i7n1\n",
    "           5657937       gpu       pd yiweiche  R 3-07:08:49      1 r2i5n1\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
