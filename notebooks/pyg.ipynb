{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'CONDA_SHLVL': '0',\n",
       "        'CONDA_EXE': '/home/ec249/ec249/bet20/miniconda3/bin/conda',\n",
       "        'SSH_CONNECTION': '146.169.169.51 59577 129.215.62.33 22',\n",
       "        'WANDB__SERVICE_WAIT': '120',\n",
       "        '_CE_M': '',\n",
       "        'USER': 'bet20',\n",
       "        'PWD': '/mnt/cephfs/ceph01/site-home/home/ec249/ec249/bet20',\n",
       "        'HOME': '/home/ec249/ec249/bet20',\n",
       "        'CONDA_PYTHON_EXE': '/home/ec249/ec249/bet20/miniconda3/bin/python',\n",
       "        'SSH_CLIENT': '146.169.169.51 59577 22',\n",
       "        '_CE_CONDA': '',\n",
       "        'SHELL': '/bin/bash',\n",
       "        'SHLVL': '5',\n",
       "        'VSCODE_AGENT_FOLDER': '/home/ec249/ec249/bet20/.vscode-server',\n",
       "        'LOGNAME': 'bet20',\n",
       "        'PATH': '/work/ec249/ec249/bet20/myenv/bin:/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/bin:/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/condabin:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/bin:/work/y07/shared/cirrus-software/gcc/10.2.0/bin:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/extras/qd/bin:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/bin:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/cuda/bin:/mnt/cephfs/ceph01/site-home/home/ec249/ec249/bet20/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/work/y07/shared/cirrus-software/git/2.37.3/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/share/Modules/bin:/work/ec249/ec249/bet20/texlive//bin/x86_64-linux:/home/ec249/ec249/bet20/miniconda3/condabin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/sbin:/bin',\n",
       "        '_': '/work/ec249/ec249/bet20/myenv/bin/python',\n",
       "        'VSCODE_HANDLES_SIGPIPE': 'true',\n",
       "        'MODULES_RUN_QUARANTINE': 'LD_LIBRARY_PATH LD_PRELOAD',\n",
       "        'LANG': 'en_US.UTF-8',\n",
       "        'HISTCONTROL': 'ignoredups',\n",
       "        'HOSTNAME': 'cirrus-login1',\n",
       "        'PATH_modshare': '/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/bin:1:/usr/bin:1:/usr/local/bin:1:/usr/share/Modules/bin:1:/work/y07/shared/cirrus-software/git/2.37.3/bin:1:/work/ec249/ec249/bet20/texlive//bin/x86_64-linux:1:/opt/sgi/bin:1:/mnt/cephfs/ceph01/site-home/home/ec249/ec249/bet20/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:1:/opt/clmgr/bin:1:/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/bin:1:/opt/sgi/sbin:1:/bin:1:/work/y07/shared/cirrus-software/gcc/10.2.0/bin:1:/opt/clmgr/sbin:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/cuda/bin:1:/home/ec249/ec249/bet20/miniconda3/condabin:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/bin:1:/sbin:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/extras/qd/bin:1:/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/condabin:1:/usr/sbin:1:/usr/local/sbin:1:/opt/c3/bin:1',\n",
       "        'LOADEDMODULES_modshare': 'nvidia/nvhpc-nompi/22.2:1:python/3.9.13-gpu:1:git/2.37.3:1:epcc/utils:1:/mnt/lustre/e1000/home/y07/shared/cirrus-modulefiles/epcc/setup-env:1:gcc/10.2.0:1:openmpi/4.1.6-cuda-11.6:1',\n",
       "        'MODULES_LMNOTUASKED_modshare': 'nvidia/nvhpc-nompi/22.2:1:git/2.37.3:1:openmpi/4.1.6-cuda-11.6:1:epcc/utils:1:gcc/10.2.0:1',\n",
       "        'S_COLORS': 'auto',\n",
       "        'C3_RSH': 'ssh -oConnectTimeout=10 -oForwardX11=no',\n",
       "        'MODULES_CMD': '/usr/share/Modules/libexec/modulecmd.tcl',\n",
       "        'MODULES_LMPREREQ': 'epcc/utils&git/2.37.3:/mnt/lustre/e1000/home/y07/shared/cirrus-modulefiles/epcc/setup-env&epcc/utils:openmpi/4.1.6-cuda-11.6&gcc/10.2.0:python/3.9.13-gpu&nvidia/nvhpc-nompi/22.2&openmpi/4.1.6-cuda-11.6',\n",
       "        'MODULES_LMCONFLICT_modshare': 'git/2.37.3&git:1:openmpi/4.1.6-cuda-11.6&openmpi:1:python/3.9.13-gpu&python:1:nvidia/nvhpc-nompi/22.2&nvhpc&nvhpc-nompi&nvhpc-byo-compiler:1:gcc/10.2.0&gcc:1',\n",
       "        '_LMFILES__modshare': '/work/y07/shared/cirrus-modulefiles/python/3.9.13-gpu:1:/work/y07/shared/cirrus-modulefiles/git/2.37.3:1:/work/y07/shared/cirrus-modulefiles/epcc/utils:1:/work/y07/shared/cirrus-modulefiles/gcc/10.2.0:1:/work/y07/shared/cirrus-modulefiles/openmpi/4.1.6-cuda-11.6:1:/mnt/lustre/e1000/home/y07/shared/cirrus-modulefiles/epcc/setup-env:1:/work/y07/shared/cirrus-modulefiles/nvidia/nvhpc-nompi/22.2:1',\n",
       "        'MODULES_LMNOTUASKED': 'git/2.37.3:epcc/utils:nvidia/nvhpc-nompi/22.2:gcc/10.2.0:openmpi/4.1.6-cuda-11.6',\n",
       "        'LOADEDMODULES': 'git/2.37.3:epcc/utils:/mnt/lustre/e1000/home/y07/shared/cirrus-modulefiles/epcc/setup-env:nvidia/nvhpc-nompi/22.2:gcc/10.2.0:openmpi/4.1.6-cuda-11.6:python/3.9.13-gpu',\n",
       "        'MODULES_LMCONFLICT': 'git/2.37.3&git:nvidia/nvhpc-nompi/22.2&nvhpc&nvhpc-nompi&nvhpc-byo-compiler:gcc/10.2.0&gcc:openmpi/4.1.6-cuda-11.6&openmpi:python/3.9.13-gpu&python',\n",
       "        'MAIL': '/var/spool/mail/bet20',\n",
       "        'MANPATH_modshare': '/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/share/man:1:/work/y07/shared/cirrus-software/git/2.37.3/share/man:1::1:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/share/man:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/man:1:/opt/clmgr/man:1:/opt/sgi/share/man:1:/work/y07/shared/cirrus-software/gcc/10.2.0/share/man:1:/opt/c3/man:1:/opt/clmgr/share/man:1:/opt/clmgr/lib/cm-cli/man:1',\n",
       "        'USE_PCM_DB': '2',\n",
       "        'LANGUAGE': 'en_US.UTF-8',\n",
       "        'MANPATH': '/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/share/man:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/share/man:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/man:/work/y07/shared/cirrus-software/git/2.37.3/share/man::/opt/c3/man:/opt/clmgr/man:/opt/sgi/share/man:/opt/clmgr/share/man:/opt/clmgr/lib/cm-cli/man:/work/y07/shared/cirrus-software/gcc/10.2.0/share/man',\n",
       "        'SLURM_EXPORT_ENV': 'all',\n",
       "        'OSCAR_HOME': '/opt/oscar',\n",
       "        'MODULEPATH': '/work/y07/shared/cirrus-modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles:/usr/share/modulefiles',\n",
       "        'MODULES_LMPREREQ_modshare': '/mnt/lustre/e1000/home/y07/shared/cirrus-modulefiles/epcc/setup-env&epcc/utils:1:openmpi/4.1.6-cuda-11.6&gcc/10.2.0:1:python/3.9.13-gpu&nvidia/nvhpc-nompi/22.2&openmpi/4.1.6-cuda-11.6:1:epcc/utils&git/2.37.3:1',\n",
       "        'MODULEPATH_modshare': '/work/y07/shared/cirrus-modulefiles:1:/usr/share/Modules/modulefiles:1:/etc/modulefiles:1:/usr/share/modulefiles:1',\n",
       "        '_LMFILES_': '/work/y07/shared/cirrus-modulefiles/git/2.37.3:/work/y07/shared/cirrus-modulefiles/epcc/utils:/mnt/lustre/e1000/home/y07/shared/cirrus-modulefiles/epcc/setup-env:/work/y07/shared/cirrus-modulefiles/nvidia/nvhpc-nompi/22.2:/work/y07/shared/cirrus-modulefiles/gcc/10.2.0:/work/y07/shared/cirrus-modulefiles/openmpi/4.1.6-cuda-11.6:/work/y07/shared/cirrus-modulefiles/python/3.9.13-gpu',\n",
       "        'MODULESHOME': '/usr/share/Modules',\n",
       "        'HISTSIZE': '100000',\n",
       "        'SBATCH_EXPORT': 'none',\n",
       "        'LESSOPEN': '||/usr/bin/lesspipe.sh %s',\n",
       "        'BASH_FUNC_module%%': '() {  unset _mlshdbg;\\n if [ \"${MODULES_SILENT_SHELL_DEBUG:-0}\" = \\'1\\' ]; then\\n case \"$-\" in \\n *v*x*)\\n set +vx;\\n _mlshdbg=\\'vx\\'\\n ;;\\n *v*)\\n set +v;\\n _mlshdbg=\\'v\\'\\n ;;\\n *x*)\\n set +x;\\n _mlshdbg=\\'x\\'\\n ;;\\n *)\\n _mlshdbg=\\'\\'\\n ;;\\n esac;\\n fi;\\n unset _mlre _mlIFS;\\n if [ -n \"${IFS+x}\" ]; then\\n _mlIFS=$IFS;\\n fi;\\n IFS=\\' \\';\\n for _mlv in ${MODULES_RUN_QUARANTINE:-};\\n do\\n if [ \"${_mlv}\" = \"${_mlv##*[!A-Za-z0-9_]}\" -a \"${_mlv}\" = \"${_mlv#[0-9]}\" ]; then\\n if [ -n \"`eval \\'echo ${\\'$_mlv\\'+x}\\'`\" ]; then\\n _mlre=\"${_mlre:-}${_mlv}_modquar=\\'`eval \\'echo ${\\'$_mlv\\'}\\'`\\' \";\\n fi;\\n _mlrv=\"MODULES_RUNENV_${_mlv}\";\\n _mlre=\"${_mlre:-}${_mlv}=\\'`eval \\'echo ${\\'$_mlrv\\':-}\\'`\\' \";\\n fi;\\n done;\\n if [ -n \"${_mlre:-}\" ]; then\\n eval `eval ${_mlre} /usr/bin/tclsh /usr/share/Modules/libexec/modulecmd.tcl bash \\'\"$@\"\\'`;\\n else\\n eval `/usr/bin/tclsh /usr/share/Modules/libexec/modulecmd.tcl bash \"$@\"`;\\n fi;\\n _mlstatus=$?;\\n if [ -n \"${_mlIFS+x}\" ]; then\\n IFS=$_mlIFS;\\n else\\n unset IFS;\\n fi;\\n unset _mlre _mlv _mlrv _mlIFS;\\n if [ -n \"${_mlshdbg:-}\" ]; then\\n set -$_mlshdbg;\\n fi;\\n unset _mlshdbg;\\n return $_mlstatus\\n}',\n",
       "        'BASH_FUNC_switchml%%': '() {  typeset swfound=1;\\n if [ \"${MODULES_USE_COMPAT_VERSION:-0}\" = \\'1\\' ]; then\\n typeset swname=\\'main\\';\\n if [ -e /usr/share/Modules/libexec/modulecmd.tcl ]; then\\n typeset swfound=0;\\n unset MODULES_USE_COMPAT_VERSION;\\n fi;\\n else\\n typeset swname=\\'compatibility\\';\\n if [ -e /usr/share/Modules/libexec/modulecmd-compat ]; then\\n typeset swfound=0;\\n MODULES_USE_COMPAT_VERSION=1;\\n export MODULES_USE_COMPAT_VERSION;\\n fi;\\n fi;\\n if [ $swfound -eq 0 ]; then\\n echo \"Switching to Modules $swname version\";\\n source /usr/share/Modules/init/bash;\\n else\\n echo \"Cannot switch to Modules $swname version, command not found\";\\n return 1;\\n fi\\n}',\n",
       "        'BASH_FUNC_ml%%': '() {  module ml \"$@\"\\n}',\n",
       "        'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess',\n",
       "        'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true',\n",
       "        'VSCODE_NLS_CONFIG': '{\"locale\":\"en\",\"osLocale\":\"en\",\"availableLanguages\":{}}',\n",
       "        'BROWSER': '/mnt/cephfs/ceph01/site-home/home/ec249/ec249/bet20/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/helpers/browser.sh',\n",
       "        'VSCODE_CWD': '/mnt/cephfs/ceph01/site-home/home/ec249/ec249/bet20',\n",
       "        'ELECTRON_RUN_AS_NODE': '1',\n",
       "        'VSCODE_IPC_HOOK_CLI': '/tmp/vscode-ipc-1cdc234a-41b4-4177-a169-2dac487056c9.sock',\n",
       "        'PYTHONUNBUFFERED': '1',\n",
       "        'LD_LIBRARY_PATH': '/work/y07/shared/cirrus-software/gcc/10.2.0/lib64:/lib64:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/lib:/work/y07/shared/cirrus-software/ucx/1.15.0-cuda-11.6/lib:/work/y07/shared/cirrus-software/pmi2/lib:/work/y07/shared/cirrus-software/libevent/2.1.12/lib:/work/y07/shared/cirrus-software/gcc/10.2.0/lib64:/work/y07/shared/cirrus-software/gcc/10.2.0/lib:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/comm_libs/nvshmem/lib:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/comm_libs/nccl/lib:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/math_libs/lib64:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/lib:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/extras/qd/lib:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/cuda/11.6/extras/CUPTI/lib64:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/cuda/lib64:/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/lib',\n",
       "        'OMPI_MCA_btl_openib_allow_ib': '1',\n",
       "        'LD_RUN_PATH_modshare': '/work/y07/shared/cirrus-software/libevent/2.1.12/lib:1:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/lib:1:/work/y07/shared/cirrus-software/ucx/1.15.0-cuda-11.6/lib:1:/work/y07/shared/cirrus-software/pmi2/lib:1',\n",
       "        'NVHPC_ROOT': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2',\n",
       "        'MINICONDA3_PYTHON_VERSION': '3.9.13',\n",
       "        'CPATH_modshare': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/comm_libs/nvshmem/include:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/math_libs/include:1:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/include:1:/work/y07/shared/cirrus-software/gcc/10.2.0/include:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/extras/qd/include/qd:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/comm_libs/nccl/include:1',\n",
       "        'PKG_CONFIG_PATH_modshare': '/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/lib/pkgconfig:1',\n",
       "        'PYTHONIOENCODING': 'utf-8',\n",
       "        'VIRTUAL_ENV': '/work/ec249/ec249/bet20/myenv',\n",
       "        'LD_LIBRARY_PATH_modshare': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/cuda/11.6/extras/CUPTI/lib64:1:/lib64:1:/work/y07/shared/cirrus-software/gcc/10.2.0/lib64:2:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/cuda/lib64:1:/work/y07/shared/cirrus-software/pmi2/lib:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/comm_libs/nvshmem/lib:1:/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/lib:1:/work/y07/shared/cirrus-software/gcc/10.2.0/lib:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/comm_libs/nccl/lib:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/math_libs/lib64:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/lib:1:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/extras/qd/lib:1:/work/y07/shared/cirrus-software/ucx/1.15.0-cuda-11.6/lib:1:/work/y07/shared/cirrus-software/libevent/2.1.12/lib:1:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/lib:1',\n",
       "        'CC': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/bin/nvc',\n",
       "        'LIBRARY_PATH_modshare': '/work/y07/shared/cirrus-software/gcc/10.2.0/lib64:1:/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/lib:1:/work/y07/shared/cirrus-software/libevent/2.1.12/lib:1:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/lib:1:/work/y07/shared/cirrus-software/ucx/1.15.0-cuda-11.6/lib:1:/work/y07/shared/cirrus-software/gcc/10.2.0/lib:1:/work/y07/shared/cirrus-software/pmi2/lib:1',\n",
       "        'OMPI_MCA_UCX_MEM_MMAP_HOOK_MODE': 'none',\n",
       "        'CPATH': '/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/include:/work/y07/shared/cirrus-software/gcc/10.2.0/include:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/extras/qd/include/qd:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/comm_libs/nvshmem/include:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/comm_libs/nccl/include:/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/math_libs/include',\n",
       "        'F77': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/bin/nvfortran',\n",
       "        'MODULES_LMALTNAME': 'gcc/10.2.0&gcc/default&gcc',\n",
       "        'OMPI_MCA_btl_openib_warn_default_gid_prefix': '0',\n",
       "        'LIBRARY_PATH': '/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/lib:/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/lib:/work/y07/shared/cirrus-software/ucx/1.15.0-cuda-11.6/lib:/work/y07/shared/cirrus-software/pmi2/lib:/work/y07/shared/cirrus-software/libevent/2.1.12/lib:/work/y07/shared/cirrus-software/gcc/10.2.0/lib64:/work/y07/shared/cirrus-software/gcc/10.2.0/lib',\n",
       "        'FC': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/bin/nvfortran',\n",
       "        'OMPI_MCA_pml': 'ucx',\n",
       "        'CXX': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/bin/nvc++',\n",
       "        'MPI_HOME': '/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6',\n",
       "        'MINICONDA3_BIN_PATH': '/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/bin',\n",
       "        'MODULES_LMALTNAME_modshare': 'gcc/10.2.0&gcc/default&gcc:1',\n",
       "        'NVHPC': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2',\n",
       "        'LD_RUN_PATH': '/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/lib:/work/y07/shared/cirrus-software/ucx/1.15.0-cuda-11.6/lib:/work/y07/shared/cirrus-software/pmi2/lib:/work/y07/shared/cirrus-software/libevent/2.1.12/lib',\n",
       "        'PYTHONPATH_modshare': '/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/lib/python3.9/site-packages:1',\n",
       "        'PYTHONPATH': '/work/y07/shared/cirrus-software/miniconda3/4.12.0-py39-gpu/lib/python3.9/site-packages',\n",
       "        'MINICONDA3_PYTHON_LABEL': 'python3.9',\n",
       "        'F90': '/work/y07/shared/cirrus-software/nvidia/hpcsdk-22.2/Linux_x86_64/22.2/compilers/bin/nvfortran',\n",
       "        'OMPI_MCA_btl_openib_if_include': 'mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_3:1',\n",
       "        'PS1': '(myenv) ',\n",
       "        'PKG_CONFIG_PATH': '/work/y07/shared/cirrus-software/openmpi/4.1.6-cuda-11.6/lib/pkgconfig',\n",
       "        'CPP': 'cpp',\n",
       "        'OMPI_MCA_opal_common_ucx_opal_mem_hooks': '1',\n",
       "        'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1',\n",
       "        'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CLICOLOR': '1',\n",
       "        'FORCE_COLOR': '1',\n",
       "        'CLICOLOR_FORCE': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_MODE: None\n"
     ]
    }
   ],
   "source": [
    "# Third-party\n",
    "import torch_geometric as pyg\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# First-party\n",
    "from neural_lam import utils\n",
    "from neural_lam.interaction_net import InteractionNet\n",
    "from neural_lam.models.base_graph_model import BaseGraphModel\n",
    "from train_model import get_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import TransformerConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_layer = TransformerConv(2, 4, heads=1, return_attention_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create multiple graphs\n",
    "edge_index1 = torch.tensor([[0, 0, 1, 1, 2, 2],\n",
    "                            [0, 1, 0, 1, 0, 1]], dtype=torch.long)\n",
    "x1 = torch.tensor([[1, 0], [0, 1], [1, 1]], dtype=torch.float)\n",
    "x2 = torch.tensor([[0, 1], [1, 1]], dtype=torch.float)\n",
    "\n",
    "x1_batch = x1.repeat(4, 1)\n",
    "x2_batch = x2.repeat(4, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 2]), torch.Size([8, 2]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_batch.size(), x2_batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, att_out = transformer_layer((x1_batch, x2_batch), edge_index1, return_attention_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 1, 1, 2, 2],\n",
       "         [0, 1, 0, 1, 0, 1]]),\n",
       " tensor([[0.3467],\n",
       "         [0.3968],\n",
       "         [0.3064],\n",
       "         [0.2530],\n",
       "         [0.3469],\n",
       "         [0.3502]], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loader = DataLoader(data_list, batch_size=2, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = TransformerConv(in_channels=2, out_channels=4, heads=1, return_attention_weights=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x, (edge_index, att_weights) = self.conv1(x, edge_index, return_attention_weights=True)\n",
    "        return x, att_weights\n",
    "\n",
    "# Initialize the model, optimizer and loss function\n",
    "model = GNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for batch_data in loader:\n",
    "    optimizer.zero_grad()\n",
    "    out, att_weights = model(batch_data)\n",
    "    print(out)\n",
    "\n",
    "    # Example target for loss computation (randomly generated for this example)\n",
    "    target = torch.tensor([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0]], dtype=torch.float)\n",
    "\n",
    "    # Compute loss and perform backpropagation\n",
    "    loss = criterion(out, target[:out.size(0)])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Loss:', loss.item())\n",
    "    break  # We break after one batch for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualization of attention weights\n",
    "def visualize_attention_weights(edge_index, att_weights):\n",
    "    edge_index = edge_index.cpu().numpy()\n",
    "    att_weights = att_weights.cpu().detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(att_weights.shape[1]):\n",
    "        plt.subplot(1, att_weights.shape[1], i + 1)\n",
    "        plt.scatter(edge_index[0], edge_index[1], s=att_weights[:, i] * 1000, alpha=0.6, edgecolors=\"r\")\n",
    "        plt.title(f'Head {i+1}')\n",
    "        plt.xlabel('Source Node')\n",
    "        plt.ylabel('Target Node')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the attention weights from the first batch\n",
    "visualize_attention_weights(edge_index, att_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args(True)\n",
    "_, graphldict = utils.load_graph(args.graph)\n",
    "_, ico_graphldict = utils.load_graph(\"uk_ico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_nets = [\n",
    "    InteractionNet(\n",
    "        graphldict[\"m2m_edge_index\"],\n",
    "        # self.m2m_edge_index,\n",
    "        args.hidden_dim,\n",
    "        hidden_layers=args.hidden_layers,\n",
    "        aggr=args.mesh_aggr,\n",
    "    )\n",
    "    for _ in range(args.processor_layers)\n",
    "]\n",
    "processor = pyg.nn.Sequential(\n",
    "    \"mesh_rep, edge_rep\",\n",
    "    [\n",
    "        (net, \"mesh_rep, mesh_rep, edge_rep -> mesh_rep, edge_rep\")\n",
    "        for net in processor_nets\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InteractionNet()\n",
      "tensor([[ 6561,  6561,  6561,  ..., 13121, 13121, 13121],\n",
      "        [   81,     1,    82,  ...,  6479,  6559,  6478]])\n",
      "InteractionNet()\n",
      "tensor([[ 6561,  6561,  6561,  ..., 13121, 13121, 13121],\n",
      "        [   81,     1,    82,  ...,  6479,  6559,  6478]])\n",
      "InteractionNet()\n",
      "tensor([[ 6561,  6561,  6561,  ..., 13121, 13121, 13121],\n",
      "        [   81,     1,    82,  ...,  6479,  6559,  6478]])\n",
      "InteractionNet()\n",
      "tensor([[ 6561,  6561,  6561,  ..., 13121, 13121, 13121],\n",
      "        [   81,     1,    82,  ...,  6479,  6559,  6478]])\n"
     ]
    }
   ],
   "source": [
    "for net in processor:\n",
    "    print(net)\n",
    "    print(net.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InteractionNet()\n",
      "tensor([[149, 149, 149,  ..., 297, 297, 297],\n",
      "        [  1,   2,   4,  ..., 144, 146, 147]])\n",
      "InteractionNet()\n",
      "tensor([[149, 149, 149,  ..., 297, 297, 297],\n",
      "        [  1,   2,   4,  ..., 144, 146, 147]])\n",
      "InteractionNet()\n",
      "tensor([[149, 149, 149,  ..., 297, 297, 297],\n",
      "        [  1,   2,   4,  ..., 144, 146, 147]])\n",
      "InteractionNet()\n",
      "tensor([[149, 149, 149,  ..., 297, 297, 297],\n",
      "        [  1,   2,   4,  ..., 144, 146, 147]])\n"
     ]
    }
   ],
   "source": [
    "for net in processor:\n",
    "    net.set_edge_index(ico_graphldict[\"m2m_edge_index\"])\n",
    "    print(net)\n",
    "    print(net.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 1, 2],\n",
       "         [2, 3, 3, 4],\n",
       "         [5, 6, 6, 7]],\n",
       "\n",
       "        [[1, 0, 2, 1],\n",
       "         [3, 2, 4, 3],\n",
       "         [6, 5, 7, 6]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the tensor (example with more than 2 rectangles)\n",
    "tensor = torch.tensor([[[0, 1, 1, 2],\n",
    "                        [1, 0, 2, 1]],\n",
    "\n",
    "                       [[2, 3, 3, 4],\n",
    "                        [3, 2, 4, 3]],\n",
    "\n",
    "                       [[5, 6, 6, 7],\n",
    "                        [6, 5, 7, 6]]])\n",
    "print(tensor.shape)\n",
    "tmp = tensor.permute(1, 0, 2)\n",
    "print(tmp.shape)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 2, 2, 3, 3, 4, 5, 6, 6, 7],\n",
       "        [1, 0, 2, 1, 3, 2, 4, 3, 6, 5, 7, 6]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tmp.reshape(tensor.shape[1], -1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Reshape the tensor to concatenate all rectangles along the second dimension\n",
    "# result = tensor.permute(1, 0, 2).reshape(tensor.shape[1], -1)\n",
    "\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data, Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = GATConv(2, 8, heads=4)\n",
    "# layer = GCNConv(2, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Data\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "edge_index=edge_index.t().contiguous()\n",
    "x = torch.tensor([[-1, 2], [0, 3], [1, 4]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create mini-batch\n",
    "x1 = torch.tensor([[-1, 3], [0, 4], [1, 5]], dtype=torch.float)\n",
    "x_batch = torch.stack([x, x1])\n",
    "\n",
    "edge_index1 = edge_index + x.shape[0]\n",
    "edge_index_batch = torch.stack([edge_index, edge_index1])\n",
    "\n",
    "print(x_batch.shape)\n",
    "print(edge_index_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.,  2.],\n",
       "         [ 0.,  3.],\n",
       "         [ 1.,  4.]],\n",
       "\n",
       "        [[-1.,  3.],\n",
       "         [ 0.,  4.],\n",
       "         [ 1.,  5.]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 1, 2],\n",
       "         [1, 0, 2, 1]],\n",
       "\n",
       "        [[3, 4, 4, 5],\n",
       "         [4, 3, 5, 4]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  2.],\n",
       "        [ 0.,  3.],\n",
       "        [ 1.,  4.],\n",
       "        [-1.,  3.],\n",
       "        [ 0.,  4.],\n",
       "        [ 1.,  5.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_b = x_batch.view(-1, x_batch.size(-1))\n",
    "print(x_b.shape)\n",
    "x_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  2.],\n",
       "        [ 0.,  3.],\n",
       "        [ 1.,  4.],\n",
       "        [-1.,  3.],\n",
       "        [ 0.,  4.],\n",
       "        [ 1.,  5.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create collated minibatch manually\n",
    "x_batch_pyg = torch.reshape(x_batch, (-1, x_batch.shape[-1]))\n",
    "print(x_batch_pyg.shape)\n",
    "x_batch_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# (B, 2, E) -> (2, B, E) -> (2, B*E)\n",
    "# edge_index_batch_pyg = torch.permute(edge_index_batch, (1, 0, 2)).reshape(2, -1)\n",
    "# print(edge_index_batch_pyg.shape)\n",
    "# edge_index_batch_pyg\n",
    "\n",
    "N_nodes = x_batch.size(1)\n",
    "batch_size = x_batch.size(0)\n",
    "edge_index_batch_pyg = torch.cat([edge_index + i * N_nodes for i in range(batch_size)], dim=1)\n",
    "\n",
    "print(edge_index_batch_pyg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[6, 2], edge_index=[2, 8], batch=[6], ptr=[3])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a minibatch using PyG Data objects\n",
    "data_list = [Data(x=x, edge_index=edge_index) for x in x_batch]\n",
    "batch = Batch.from_data_list(data_list)\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  2.],\n",
       "        [ 0.,  3.],\n",
       "        [ 1.,  4.],\n",
       "        [-1.,  3.],\n",
       "        [ 0.,  4.],\n",
       "        [ 1.,  5.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 2, 0, 3, 4, 4, 5, 3],\n",
       "        [1, 0, 2, 1, 2, 4, 3, 5, 4, 5]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(torch.isclose(x_batch_pyg, batch.x).all())\n",
    "print(torch.isclose(edge_index_batch_pyg, batch.edge_index).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch = layer(batch.x, batch.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 32])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 32])\n"
     ]
    }
   ],
   "source": [
    "y_b = torch.reshape(y_batch, (x_batch.shape[0], x_batch.shape[1], -1))\n",
    "print(y_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Define the dimensions\n",
    "N_rec = 50\n",
    "N_send = 50\n",
    "d_h = 10\n",
    "\n",
    "# Create the tensors\n",
    "rec_rep = torch.randn(N_rec, d_h)\n",
    "send_rep = torch.randn(N_send, d_h)\n",
    "\n",
    "# Concatenate the tensors\n",
    "node_reps = torch.cat((rec_rep, send_rep), dim=-2)\n",
    "\n",
    "# Print the shape of the resulting tensor\n",
    "print(node_reps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.empty(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        \n",
    "        print(\"edge_index.shape\")\n",
    "        print(edge_index.shape)\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # [2, E] -> [2, E + N]\n",
    "        print(\"edge_index.shape (self loops added)\")\n",
    "        print(edge_index.shape)\n",
    "        \n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x) # [N, in_channels] -> [N, out_channels]\n",
    "        print(\"x.shape\")\n",
    "        print(x.shape)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "\n",
    "        # Diagonal of degree matrix (all elements not on diagonal are 0)\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype) # [N]\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        print(\"degree shapes\")\n",
    "        print(deg.shape)\n",
    "        print(deg_inv_sqrt.shape)\n",
    "        \n",
    "        # Elementwise multiplication\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col] # [E]\n",
    "        print(\"norm.shape\")\n",
    "        print(norm.shape)\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        # calculate message by passing x, norm to self.message() (internally)\n",
    "        # for each node, use edge_index to determine incoming messages\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # calculates the message for node i (that is, x_i)\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        \n",
    "        print(\"x_j.shape\")\n",
    "        print(x_j.shape)\n",
    "        print(\"norm.view(-1, 1).shape\")\n",
    "        print(norm.view(-1, 1).shape)\n",
    "        print(\"message shape\")\n",
    "        print((norm.view(-1, 1) * x_j).shape)\n",
    "        return norm.view(-1, 1) * x_j\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        print(\"aggr_out.shape\")\n",
    "        print(aggr_out.shape)\n",
    "        print(\"x.shape\")\n",
    "        print(x.shape)\n",
    "        return aggr_out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index.shape\n",
      "torch.Size([2, 11])\n",
      "edge_index.shape (self loops added)\n",
      "torch.Size([2, 21])\n",
      "x.shape\n",
      "torch.Size([10, 128])\n",
      "degree shapes\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "norm.shape\n",
      "torch.Size([21])\n",
      "x_j.shape\n",
      "torch.Size([21, 128])\n",
      "norm.view(-1, 1).shape\n",
      "torch.Size([21, 1])\n",
      "message shape\n",
      "torch.Size([21, 128])\n",
      "aggr_out.shape\n",
      "torch.Size([10, 128])\n",
      "x.shape\n",
      "torch.Size([10, 128])\n",
      "tensor([[ 0.5136, -0.7564, -0.1948,  ..., -0.0750,  0.2263, -0.8994],\n",
      "        [ 0.5533, -0.5819, -0.0547,  ...,  0.6010, -0.3274, -0.3957],\n",
      "        [ 0.3818,  0.1921,  0.9273,  ..., -0.3475, -0.1355, -0.7313],\n",
      "        ...,\n",
      "        [-0.0356,  0.4850, -0.4018,  ..., -0.4825,  0.5431,  1.2539],\n",
      "        [-1.2525,  0.2215,  0.4838,  ..., -0.0128,  0.4759,  0.0181],\n",
      "        [ 0.4090, -0.0837, -0.1797,  ...,  0.2653, -0.4348, -0.2556]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([10, 128])\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of GCNConv\n",
    "gcn = GCNConv(in_channels=64, out_channels=128)\n",
    "\n",
    "# Create sample input data\n",
    "x = torch.randn(10, 64)  # Node feature matrix\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8],\n",
    "                           [1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 7]])  # Edge indices\n",
    "\n",
    "# Pass the input data through GCNConv\n",
    "output = gcn(x, edge_index)\n",
    "\n",
    "# Print the output\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 168], x=[37, 21], y=[1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 4388], x=[1228, 21], y=[32], batch=[1228], ptr=[33])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch.num_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch.batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 21])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import scatter\n",
    "\n",
    "\n",
    "x = scatter(batch.x, batch.batch, dim=0, reduce='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 21])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
